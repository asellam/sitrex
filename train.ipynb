{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/your-username/your-repo.git\n",
    "%cd your-repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6fubIm76ZdW"
   },
   "source": [
    "# Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZt0APPizmv5"
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download('abdellah213/sitrex-dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbuBNCCw69KI"
   },
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p0IEFaNKzz3F"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sitrex.preprocessing import load_dataset, preprocess_data, SimilarityDataset, UsefulnessDataset\n",
    "from sitrex.model import angle_usefulness_model, angle_similarity_model, TQDMProgressBar\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "# Define constants\n",
    "DATASET_PATH = os.path.join(path, 'dataset')\n",
    "# EarlyStop save path for the Siamese Transformer\n",
    "MODEL_SAVE_PATH_SIMILARITY = './angle_similarity_model.keras'\n",
    "# EarlyStop save path for the Angle Usefulness Transformer\n",
    "MODEL_SAVE_PATH_USEFULNESS = './angle_usefulness_model.keras'\n",
    "# Maximum sequence length (L)\n",
    "MAXLEN = 100\n",
    "# Batch Size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMNQw9Ql7_YW",
    "outputId": "f0eccd89-1d23-4f28-e2e8-cb530fe22688"
   },
   "outputs": [],
   "source": [
    "all_sequences, labels, exercise_angles = load_dataset(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8Fvh4Ak7Hnw"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3XNnuaE8P0H"
   },
   "outputs": [],
   "source": [
    "processed_sequences, numerical_labels, label_angles = preprocess_data(all_sequences, labels, exercise_angles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1-x8hJi8Wxz"
   },
   "source": [
    "# Tensorflow Dataset and Model Routines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAfoMcUK9ceH"
   },
   "source": [
    "# K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45B5HZpO9Vl9"
   },
   "outputs": [],
   "source": [
    "def split_by_fold(data_x, data_y, folds, test):\n",
    "    train_x, test_x, train_y, test_y = [], [], [], []\n",
    "    for fold, split in enumerate(folds):\n",
    "        for sample in split:\n",
    "            if fold == test:\n",
    "                test_x.append(data_x[sample])\n",
    "                test_y.append(data_y[sample])\n",
    "            else:\n",
    "                train_x.append(data_x[sample])\n",
    "                train_y.append(data_y[sample])\n",
    "    return train_x, test_x, train_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DOFTlTJZ9wRL",
    "outputId": "938521d5-d181-42e7-f06d-70db856d3172"
   },
   "outputs": [],
   "source": [
    "# Preparing the 5 folds\n",
    "k = 5\n",
    "N = len(numerical_labels)\n",
    "indexes = np.arange(N)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indexes)\n",
    "\n",
    "fold_size = int(np.ceil(N / k))\n",
    "\n",
    "folds = []\n",
    "for i in range(k):\n",
    "    start = i * fold_size\n",
    "    end = min(start + fold_size, N)\n",
    "    folds.append(indexes[start:end])\n",
    "\n",
    "print(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCF9f-Il-Bv4",
    "outputId": "9413bebe-179c-46e9-ca08-2e2fea78dd65"
   },
   "outputs": [],
   "source": [
    "for seq_module in ['gru', 'lstm', 'transformer']:\n",
    "    print(f'Performing k-fold cross-validation for the Angle Usefulness {seq_module} ...')\n",
    "    for test in range(k):\n",
    "        print(f'Testing on Fold #{test+1}/{k} ...')\n",
    "        X_train, X_test, y_train, y_test = split_by_fold(\n",
    "            processed_sequences,\n",
    "            numerical_labels,\n",
    "            folds,\n",
    "            test\n",
    "        )\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            test_size=0.2,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        y_train = np.array(y_train, dtype=np.int32)\n",
    "        y_test = np.array(y_test, dtype=np.int32)\n",
    "        y_val = np.array(y_val, dtype=np.int32)\n",
    "\n",
    "        Y_train = np.empty((len(X_train), len(X_train[0][0])), np.float32)\n",
    "        Y_val = np.empty((len(X_val), len(X_train[0][0])), np.float32)\n",
    "        Y_test = np.empty((len(X_test), len(X_train[0][0])), np.float32)\n",
    "\n",
    "        for (Y, y) in [(Y_train, y_train), (Y_val, y_val), (Y_test, y_test)]:\n",
    "            for i in range(Y.shape[0]):\n",
    "                for angle in range(Y.shape[1]):\n",
    "                    if angle in label_angles[y[i]]:\n",
    "                        Y[i, angle] = 1\n",
    "                    else:\n",
    "                        Y[i, angle] = 0\n",
    "\n",
    "        usefulness_model = angle_usefulness_model(maxlen=MAXLEN, module=seq_module, lr=1e-3)\n",
    "\n",
    "        pbar_callback = TQDMProgressBar(epochs=80)\n",
    "\n",
    "        callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            MODEL_SAVE_PATH_USEFULNESS,\n",
    "            monitor=\"val_binary_accuracy\",\n",
    "            verbose=0,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode=\"max\",\n",
    "            save_freq=\"epoch\",\n",
    "            initial_value_threshold=None,\n",
    "        )\n",
    "\n",
    "        train_ds = UsefulnessDataset(X_train, Y_train, y_train, batch_size=batch_size, maxlen=MAXLEN, train=True)\n",
    "        val_ds = UsefulnessDataset(X_val, Y_val, y_val, batch_size=min(batch_size, len(X_val)), maxlen=MAXLEN, train=False)\n",
    "\n",
    "        history = usefulness_model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            batch_size=batch_size,\n",
    "            epochs=80,\n",
    "            callbacks=[callback, pbar_callback],\n",
    "            verbose=0, # Change this to 1 if you want progressive display while training\n",
    "        )\n",
    "\n",
    "        # Load the trained classifier model\n",
    "        usefulness_model = tf.keras.models.load_model(\n",
    "            MODEL_SAVE_PATH_USEFULNESS\n",
    "        )\n",
    "\n",
    "        test_ds = UsefulnessDataset(X_test, Y_test, y_test, batch_size=batch_size, maxlen=MAXLEN, train=False)\n",
    "        usefulness_model.evaluate(test_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m8tPsAjN_JAe",
    "outputId": "e2b7ff64-16ae-4e58-acbc-5df183cece27"
   },
   "outputs": [],
   "source": [
    "for seq_module in ['gru', 'lstm', 'transformer']:\n",
    "    print(f'Performing k-fold cross-validation for the Siamese {seq_module} ...')\n",
    "    for test in range(k):\n",
    "        print(f'Testing on Fold #{test+1}/{k} ...')\n",
    "        X_train, X_test, y_train, y_test = split_by_fold(\n",
    "            processed_sequences,\n",
    "            numerical_labels,\n",
    "            folds,\n",
    "            test\n",
    "        )\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            test_size=0.2,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        y_train = np.array(y_train, dtype=np.int32)\n",
    "        y_test = np.array(y_test, dtype=np.int32)\n",
    "        y_val = np.array(y_val, dtype=np.int32)\n",
    "\n",
    "        train_batches = 10 * len(X_train) // batch_size\n",
    "        val_batches = 10 * len(X_val) // batch_size\n",
    "        train_ds = SimilarityDataset(X_train, y_train, num_batches=train_batches, batch_size=batch_size, label_angles=label_angles, maxlen=MAXLEN, train=True)\n",
    "        val_ds = SimilarityDataset(X_val, y_val, num_batches=val_batches, batch_size=batch_size, label_angles=label_angles, maxlen=MAXLEN, train=False)\n",
    "\n",
    "        callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            MODEL_SAVE_PATH_SIMILARITY,\n",
    "            monitor=\"val_binary_accuracy\",\n",
    "            verbose=0,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode=\"max\",\n",
    "            save_freq=\"epoch\",\n",
    "            initial_value_threshold=None,\n",
    "        )\n",
    "\n",
    "        pbar_callback = TQDMProgressBar(epochs=60)\n",
    "\n",
    "        # Build and train Siamese model\n",
    "        similarity_model = angle_similarity_model(maxlen=MAXLEN, module=seq_module, lr=1e-3)\n",
    "        history = similarity_model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=60,\n",
    "            callbacks=[callback, pbar_callback],\n",
    "            verbose=0,  # Change this to 1 if you want progressive display while training\n",
    "        )\n",
    "\n",
    "        similarity_model = tf.keras.models.load_model(\n",
    "            MODEL_SAVE_PATH_SIMILARITY,\n",
    "        )\n",
    "\n",
    "        # Make a large dataset in terms of pair in order to have a more reliable test\n",
    "        # since we can't test on all possible pairs (very huge number)\n",
    "        test_batches = 1000 * len(X_test) // batch_size\n",
    "        # Evaluate the Siamese model on the test set\n",
    "        test_ds = SimilarityDataset(X_test, y_test, num_batches=test_batches, batch_size=batch_size, label_angles=label_angles, maxlen=MAXLEN, train=False)\n",
    "        similarity_model.evaluate(test_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ncJ_OCo_1ej"
   },
   "source": [
    "# One-shot Generalization Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M3UuYgIW_0kd"
   },
   "outputs": [],
   "source": [
    "tests = [[3, 4, 13, 14, 15, 17], [1, 3, 4, 13, 14, 20], [1, 3, 6, 13, 19, 20], [1, 3, 7, 13, 14, 16], [1, 3, 5, 13, 14, 19], [1, 2, 3, 13, 19, 21], [0, 3, 6, 7, 13, 19], [1, 3, 4, 13, 14, 21], [3, 7, 13, 14, 16, 17], [1, 3, 10, 13, 20, 21]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJar4K7_ADxQ"
   },
   "outputs": [],
   "source": [
    "# Function to split data by specifying test labels\n",
    "def split_by_labels(data_x, data_y, test_labels):\n",
    "    X_train, X_test, y_train, y_test = [], [], [], []\n",
    "    for sample_x, sample_y in zip(data_x, data_y):\n",
    "        if sample_y in test_labels:\n",
    "            X_test.append(sample_x)\n",
    "            y_test.append(sample_y)\n",
    "        else:\n",
    "            X_train.append(sample_x)\n",
    "            y_train.append(sample_y)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JwMU3IQgAq5-"
   },
   "outputs": [],
   "source": [
    "print('Performing one-shot validation for the Angle Usefulness Transformer ...')\n",
    "for test in tests:\n",
    "    print(f'Testing on Exercises: {test} ...')\n",
    "    X_train, X_test, y_train, y_test = split_by_labels(\n",
    "        processed_sequences,\n",
    "        numerical_labels,\n",
    "        test_labels=test,\n",
    "    )\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    y_train = np.array(y_train, dtype=np.int32)\n",
    "    y_test = np.array(y_test, dtype=np.int32)\n",
    "    y_val = np.array(y_val, dtype=np.int32)\n",
    "\n",
    "    Y_train = np.empty((len(X_train), len(X_train[0][0])), np.float32)\n",
    "    Y_val = np.empty((len(X_val), len(X_train[0][0])), np.float32)\n",
    "    Y_test = np.empty((len(X_test), len(X_train[0][0])), np.float32)\n",
    "\n",
    "    for (Y, y) in [(Y_train, y_train), (Y_val, y_val), (Y_test, y_test)]:\n",
    "        for i in range(Y.shape[0]):\n",
    "            for angle in range(Y.shape[1]):\n",
    "                if angle in label_angles[y[i]]:\n",
    "                    Y[i, angle] = 1\n",
    "                else:\n",
    "                    Y[i, angle] = 0\n",
    "\n",
    "    usefulness_model = angle_usefulness_model(maxlen=MAXLEN, module='transformer', lr=1e-4)\n",
    "\n",
    "    callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        MODEL_SAVE_PATH_USEFULNESS,\n",
    "        monitor=\"val_binary_accuracy\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode=\"max\",\n",
    "        save_freq=\"epoch\",\n",
    "        initial_value_threshold=None,\n",
    "    )\n",
    "\n",
    "    pbar_callback = TQDMProgressBar(epochs=80)\n",
    "\n",
    "    train_ds = UsefulnessDataset(X_train, Y_train, y_train, batch_size=batch_size, maxlen=MAXLEN, train=True)\n",
    "    val_ds = UsefulnessDataset(X_val, Y_val, y_val, batch_size=min(batch_size, len(X_val)), maxlen=MAXLEN, train=False)\n",
    "\n",
    "    history = usefulness_model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        batch_size=batch_size,\n",
    "        epochs=80,\n",
    "        callbacks=[callback, pbar_callback],\n",
    "        verbose=0,  # Change this to 1 if you want progressive display while training\n",
    "    )\n",
    "\n",
    "    # Load the trained classifier model\n",
    "    usefulness_model = tf.keras.models.load_model(\n",
    "        MODEL_SAVE_PATH_USEFULNESS\n",
    "    )\n",
    "\n",
    "    test_ds = UsefulnessDataset(X_test, Y_test, y_test, batch_size=batch_size, maxlen=MAXLEN, train=False)\n",
    "    usefulness_model.evaluate(test_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFhxjwVJARTw"
   },
   "outputs": [],
   "source": [
    "print('Performing one-shot validation for the Siamese Transformer ...')\n",
    "for test in tests:\n",
    "    print(f'Testing on Exercises: {test} ...')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_by_labels(\n",
    "        processed_sequences,\n",
    "        numerical_labels,\n",
    "        test_labels=test,\n",
    "    )\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    train_batches = 10 * len(X_train) // batch_size\n",
    "    val_batches = 10 * len(X_val) // batch_size\n",
    "    train_ds = SimilarityDataset(X_train, y_train, num_batches=train_batches, batch_size=batch_size, label_angles=label_angles, maxlen=MAXLEN, train=True)\n",
    "    val_ds = SimilarityDataset(X_val, y_val, num_batches=val_batches, batch_size=batch_size, label_angles=label_angles, maxlen=MAXLEN, train=False)\n",
    "\n",
    "    callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        MODEL_SAVE_PATH_SIMILARITY,\n",
    "        monitor=\"val_binary_accuracy\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode=\"max\",\n",
    "        save_freq=\"epoch\",\n",
    "        initial_value_threshold=None,\n",
    "    )\n",
    "\n",
    "    pbar_callback = TQDMProgressBar(epochs=60)\n",
    "\n",
    "    # Build and train Siamese model\n",
    "    similarity_model = angle_similarity_model(maxlen=MAXLEN, module='transformer', lr=1e-3)\n",
    "    history = similarity_model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=60,\n",
    "        callbacks=[callback, pbar_callback],\n",
    "        verbose=0,  # Change this to 1 if you want progressive display while training\n",
    "    )\n",
    "\n",
    "    # Load the trained Siamese model\n",
    "    similarity_model = tf.keras.models.load_model(\n",
    "        MODEL_SAVE_PATH_SIMILARITY,\n",
    "    )\n",
    "\n",
    "    # Make a large dataset in terms of pair in order to have a more reliable test\n",
    "    # since we can't test on all possible pairs (very huge number)\n",
    "    test_batches = 1000 * len(X_test) // batch_size\n",
    "    # Evaluate the Siamese model on the test set\n",
    "    test_ds = SimilarityDataset(X_test, y_test, num_batches=test_batches, batch_size=batch_size, label_angles=label_angles, maxlen=MAXLEN, train=False)\n",
    "    similarity_model.evaluate(test_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
