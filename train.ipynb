{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_HAe5VzbUd7"
      },
      "source": [
        "# Get the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA7POIpDbUd8",
        "outputId": "3c825808-ce4d-4831-cfea-983e0932b0e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sitrex'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 146 (delta 77), reused 99 (delta 45), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (146/146), 1.78 MiB | 10.19 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n",
            "/content/sitrex\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/asellam/sitrex.git\n",
        "%cd sitrex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QTceCwapbUd_",
        "outputId": "6bcdac3a-84d4-45aa-9acb-240e7beefb80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<2.0,>=1.23 (from -r requirements.txt (line 2))\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (1.16.1)\n",
            "Requirement already satisfied: tqdm>=4.65 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (1.6.1)\n",
            "Requirement already satisfied: kagglehub>=0.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (0.3.13)\n",
            "Collecting mediapipe==0.10.21 (from -r requirements.txt (line 15))\n",
            "  Downloading mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (0.5.3)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (0.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (3.10.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (4.12.0.88)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe==0.10.21->-r requirements.txt (line 15))\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe==0.10.21->-r requirements.txt (line 15))\n",
            "  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (0.2.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->-r requirements.txt (line 9)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->-r requirements.txt (line 9)) (3.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub>=0.2->-r requirements.txt (line 12)) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub>=0.2->-r requirements.txt (line 12)) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub>=0.2->-r requirements.txt (line 12)) (2.32.4)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.21->-r requirements.txt (line 15)) (2.0.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe==0.10.21->-r requirements.txt (line 15)) (0.5.3)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe==0.10.21->-r requirements.txt (line 15)) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (2.9.0.post0)\n",
            "INFO: pip is looking at multiple versions of opencv-contrib-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-contrib-python (from mediapipe==0.10.21->-r requirements.txt (line 15))\n",
            "  Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub>=0.2->-r requirements.txt (line 12)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub>=0.2->-r requirements.txt (line 12)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub>=0.2->-r requirements.txt (line 12)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub>=0.2->-r requirements.txt (line 12)) (2025.8.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.21->-r requirements.txt (line 15)) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (1.17.0)\n",
            "Downloading mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\n",
            "Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, numpy, sounddevice, opencv-contrib-python, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.12.0.88\n",
            "    Uninstalling opencv-contrib-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-contrib-python-4.12.0.88\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.21 numpy-1.26.4 opencv-contrib-python-4.11.0.86 protobuf-4.25.8 sounddevice-0.5.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              },
              "id": "f5eadea9bfc5446bbb8a9c4cbd1b748a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After session restart, continue running from this cell not from the beginning\n",
        "%cd sitrex"
      ],
      "metadata": {
        "id": "vKPejVM9Pixn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "269007ca-d52d-447e-9c8e-51547f7d927b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sitrex\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6fubIm76ZdW"
      },
      "source": [
        "# Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZt0APPizmv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee78f7b1-a37c-48a1-dfbe-5d47c500833f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/abdellah213/sitrex-dataset?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 418M/418M [00:03<00:00, 127MB/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download('abdellah213/sitrex-dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbuBNCCw69KI"
      },
      "source": [
        "# Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0IEFaNKzz3F"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('.')\n",
        "# Import necessary libraries\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sitrex.preprocessing import load_dataset, preprocess_data, SimilarityDataset, UsefulnessDataset\n",
        "from sitrex.model import angle_usefulness_model, angle_similarity_model, TQDMProgressBar\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "# Define constants\n",
        "DATASET_PATH = os.path.join(path, 'dataset')\n",
        "# EarlyStop save path for the Siamese Transformer\n",
        "MODEL_SAVE_PATH_SIMILARITY = './angle_similarity_model.weights.h5'\n",
        "# EarlyStop save path for the Angle Usefulness Transformer\n",
        "MODEL_SAVE_PATH_USEFULNESS = './angle_usefulness_model.weights.h5'\n",
        "# Maximum sequence length (L)\n",
        "MAXLEN = 100\n",
        "# Batch Size\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELxuOym7bUeA"
      },
      "source": [
        "# Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<u>**angle_type:**</u>\n",
        "\n",
        "*   **unsigned:** Unsigned joint angles calculated using arccos\n",
        "*   **signed:** Signed joint angles calculated using arctan2 without projection on any anatomical plane\n",
        "*   **max-energy:** Signed joint angles calculated using arctan2 after projection the anatomical plane that introduces maximum variance in angle values over the temporal sequence\n",
        "*   **sagittal:** Signed joint angles calculated using arctan2 after projection the sagittal anatomical plane\n",
        "*   **coronal:** Signed joint angles calculated using arctan2 after projection the coronal (frontal) anatomical plane\n",
        "*   **transverse:** Signed joint angles calculated using arctan2 after projection the transverse anatomical plane\n",
        "*   **all:** Three signed angles per joint calculated using arctan2 after projection all three anatomical plane"
      ],
      "metadata": {
        "id": "DKCkkzE1OEdh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMNQw9Ql7_YW",
        "outputId": "74b19880-8dc4-44a1-f6f0-1b14437e3ed8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dataset: 100%|██████████| 727/727 [11:45<00:00,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 727 sequences with labels.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "all_sequences, labels, exercise_angles = load_dataset(DATASET_PATH, angle_type='sagittal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8Fvh4Ak7Hnw"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3XNnuaE8P0H"
      },
      "outputs": [],
      "source": [
        "processed_sequences, numerical_labels, label_angles = preprocess_data(all_sequences, labels, exercise_angles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1-x8hJi8Wxz"
      },
      "source": [
        "# Tensorflow Dataset and Model Routines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAfoMcUK9ceH"
      },
      "source": [
        "# K-Fold Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45B5HZpO9Vl9"
      },
      "outputs": [],
      "source": [
        "def split_by_fold(data_x, data_y, folds, test):\n",
        "    train_x, test_x, train_y, test_y = [], [], [], []\n",
        "    for fold, split in enumerate(folds):\n",
        "        for sample in split:\n",
        "            if fold == test:\n",
        "                test_x.append(data_x[sample])\n",
        "                test_y.append(data_y[sample])\n",
        "            else:\n",
        "                train_x.append(data_x[sample])\n",
        "                train_y.append(data_y[sample])\n",
        "    return train_x, test_x, train_y, test_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOFTlTJZ9wRL",
        "outputId": "59741d68-2e0f-429d-dd83-7eb2988c8b58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([513, 693, 377,  33,  63, 467, 346, 511, 148, 388, 174,  65, 469,\n",
            "       428, 707, 350, 210,  72, 449,  78,  54,  39,  97, 211,  81, 557,\n",
            "       629, 443, 514,  10, 361, 319, 676, 673, 231, 363, 158, 462, 296,\n",
            "       578, 723, 396,  86, 329, 597, 235, 351, 568, 299, 685, 165, 571,\n",
            "       164, 223, 539, 399, 281, 227, 714, 620, 199, 705, 155,  49, 332,\n",
            "       101, 477, 234, 437, 196,  23, 266,  77, 212, 198, 109, 713, 327,\n",
            "       528, 336, 209,  30, 602, 674, 480, 554, 393, 547, 118, 609, 133,\n",
            "       688,  84,  79, 213, 433, 448, 181,  31, 254, 598, 215, 412, 591,\n",
            "       275,  55, 679, 594, 691, 300,  76,   2, 506, 464, 192,  60, 722,\n",
            "       120, 362, 429, 314, 218, 220, 634, 260, 405, 244, 426, 431,  90,\n",
            "       331, 538,  69, 204, 131,  44,  70, 349, 717, 569, 135, 601, 239,\n",
            "       579, 642, 432]), array([136, 286,   6, 657, 587, 334, 250, 145, 338, 132, 306, 660,  41,\n",
            "       108, 292,  56, 417, 690, 333, 537,  24, 404, 465, 666, 311, 457,\n",
            "       110,  82,  51, 394, 582, 497, 290, 265, 501, 650, 603,  18, 342,\n",
            "       369, 694,  83,  61, 533, 625,  29, 584, 710, 678, 367, 182, 482,\n",
            "       604, 408, 585, 381, 208, 264, 436, 589, 176, 294, 259, 530, 248,\n",
            "       137, 409, 680, 163, 425, 637, 483, 581, 324, 328, 450, 104, 114,\n",
            "       652, 575, 651, 424,  92,   7,  89, 551, 356, 479, 544, 515, 453,\n",
            "       247, 140,  28,  43,  42,  73, 167, 398, 635,  66,  11, 335, 627,\n",
            "       178, 645, 456, 446, 355, 526, 177, 622, 628, 257, 291,  15, 422,\n",
            "       256, 302, 318, 623, 451, 340, 430, 375,   9, 249,  22, 221, 655,\n",
            "       711, 687, 607, 203, 440,  93, 326, 535, 416, 284, 184, 586, 323,\n",
            "       153,  75, 371]), array([277,  68, 420, 188, 271, 236,  88, 615, 117, 125, 596, 289, 238,\n",
            "         0, 718, 344, 632, 380, 278, 116, 228, 633, 357, 274, 487, 144,\n",
            "       423, 542, 656, 529, 268, 512, 307, 310,  46, 261, 195, 726, 608,\n",
            "       107, 507, 543, 360, 100, 390, 649, 527, 704, 179, 304, 352, 658,\n",
            "       698, 149, 124, 599, 630, 185, 708, 725, 382, 716, 500, 321, 353,\n",
            "       669, 142, 141, 434, 320,  19, 172, 590, 312, 675,  12, 305, 354,\n",
            "        25, 541, 169,  38, 445, 245, 298, 478, 272, 154, 126, 516, 341,\n",
            "       287, 113, 485, 173, 359, 395,  57, 519, 222, 280,  17, 447, 322,\n",
            "       255, 699, 696, 190, 595, 641, 411,  94, 180, 301, 470, 534, 665,\n",
            "       558, 640, 473,   5, 712,  45, 439, 548, 171,  16,  48, 702, 664,\n",
            "         3, 494, 667, 316, 668, 283,  96, 285, 481, 225,  26, 570, 263,\n",
            "        50, 364, 229]), array([ 37, 157, 237, 697, 374, 370, 442, 175, 616, 127, 536, 194, 618,\n",
            "       626, 468, 490, 493, 701, 605, 624,  67, 486, 168, 444, 639, 162,\n",
            "       309, 193, 518, 365, 383, 654, 525, 152, 495, 517, 522, 226, 606,\n",
            "       580, 103, 421, 419, 567, 550,  74, 115, 407, 721, 119,  53, 151,\n",
            "       403, 683, 207, 503, 521, 611, 695,   8, 588,  36, 452, 139, 253,\n",
            "       303, 610, 549, 368,  59, 499, 684, 111, 523, 531, 262, 297, 414,\n",
            "       150, 576, 644, 488, 147, 146, 532, 672, 545, 348, 463, 325, 186,\n",
            "       123, 617, 143, 692, 197, 279, 293, 400, 122, 183, 202, 438, 246,\n",
            "       415, 643, 129, 402, 572, 671, 219, 659, 552, 662, 559, 386, 703,\n",
            "       509, 267, 441, 496, 112, 232, 631, 373, 233, 583, 317, 410, 648,\n",
            "       358, 258, 282, 376, 384, 224, 689, 593, 472, 347, 505, 715, 670,\n",
            "       653, 619, 612]), array([556, 577,  85, 242, 159, 524,  35, 540, 170, 621, 613, 682,  95,\n",
            "       563, 240, 574, 460, 553, 636, 206, 392, 397, 719, 217,   4, 647,\n",
            "       546,  98, 573, 406, 502,  47,  32, 200, 134,  27, 638, 230, 489,\n",
            "       378, 288, 418, 391, 592, 498, 138,  62, 471, 128, 706, 520,  64,\n",
            "        14, 156,  40, 492, 379, 187, 216,  52, 337, 295, 251, 461, 455,\n",
            "       724, 269, 201, 161, 555, 401, 476, 105, 565, 389,   1, 677, 561,\n",
            "        80, 205,  34, 508, 427, 454, 366,  91, 339, 564, 345, 241,  13,\n",
            "       315, 600, 387, 273, 166, 720, 646, 484, 709, 504, 243, 566, 562,\n",
            "       686, 189, 475, 681, 510,  58, 474, 560, 252,  21, 313, 459, 160,\n",
            "       276, 191, 385, 413, 491, 343, 308, 661, 130, 663,  99, 372,  87,\n",
            "       458, 330, 214, 466, 121, 614,  20, 700,  71, 106, 270, 435, 102])]\n"
          ]
        }
      ],
      "source": [
        "# Preparing the 5 folds\n",
        "k = 5\n",
        "N = len(numerical_labels)\n",
        "indexes = np.arange(N)\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(indexes)\n",
        "\n",
        "fold_size = int(np.ceil(N / k))\n",
        "\n",
        "folds = []\n",
        "for i in range(k):\n",
        "    start = i * fold_size\n",
        "    end = min(start + fold_size, N)\n",
        "    folds.append(indexes[start:end])\n",
        "\n",
        "print(folds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCF9f-Il-Bv4",
        "outputId": "0ab3fb88-b9b2-4e4c-fdb9-5d64fd805e8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing k-fold cross-validation for the Angle Usefulness gru ...\n",
            "Testing on Fold #1/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [01:11<00:00,  1.13epoch/s, Precision=0.8370, Recall=0.6948, binary_accuracy=0.8962, loss=0.2481, val_Precision=0.7201, val_Recall=0.5434, val_binary_accuracy=0.8225, val_loss=0.3770]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - Precision: 0.7561 - Recall: 0.6143 - binary_accuracy: 0.8510 - loss: 0.3460\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing on Fold #2/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [01:10<00:00,  1.14epoch/s, Precision=0.8194, Recall=0.6861, binary_accuracy=0.8906, loss=0.2587, val_Precision=0.7785, val_Recall=0.5939, val_binary_accuracy=0.8474, val_loss=0.3459]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Precision: 0.7821 - Recall: 0.5301 - binary_accuracy: 0.8377 - loss: 0.3680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing on Fold #3/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [00:59<00:00,  1.35epoch/s, Precision=0.8221, Recall=0.6539, binary_accuracy=0.8855, loss=0.2782, val_Precision=0.7656, val_Recall=0.5443, val_binary_accuracy=0.8410, val_loss=0.3430]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - Precision: 0.7449 - Recall: 0.5100 - binary_accuracy: 0.8137 - loss: 0.4049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing on Fold #4/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [01:08<00:00,  1.17epoch/s, Precision=0.8229, Recall=0.6833, binary_accuracy=0.8911, loss=0.2555, val_Precision=0.7298, val_Recall=0.5633, val_binary_accuracy=0.8361, val_loss=0.3553]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - Precision: 0.7964 - Recall: 0.6332 - binary_accuracy: 0.8637 - loss: 0.3247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing on Fold #5/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [01:08<00:00,  1.17epoch/s, Precision=0.8376, Recall=0.6930, binary_accuracy=0.8961, loss=0.2498, val_Precision=0.8170, val_Recall=0.6421, val_binary_accuracy=0.8705, val_loss=0.2917]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - Precision: 0.7682 - Recall: 0.5949 - binary_accuracy: 0.8451 - loss: 0.3539"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - Precision: 0.7889 - Recall: 0.5934 - binary_accuracy: 0.8523 - loss: 0.3332\n",
            "Performing k-fold cross-validation for the Angle Usefulness lstm ...\n",
            "Testing on Fold #1/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [01:07<00:00,  1.19epoch/s, Precision=0.8507, Recall=0.7312, binary_accuracy=0.9066, loss=0.2230, val_Precision=0.7727, val_Recall=0.5792, val_binary_accuracy=0.8428, val_loss=0.3376]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - Precision: 0.7903 - Recall: 0.6867 - binary_accuracy: 0.8736 - loss: 0.3026\n",
            "Testing on Fold #2/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [01:10<00:00,  1.13epoch/s, Precision=0.8501, Recall=0.7483, binary_accuracy=0.9098, loss=0.2150, val_Precision=0.7746, val_Recall=0.6462, val_binary_accuracy=0.8564, val_loss=0.3231]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Precision: 0.7793 - Recall: 0.6233 - binary_accuracy: 0.8544 - loss: 0.3471\n",
            "Testing on Fold #3/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [01:03<00:00,  1.25epoch/s, Precision=0.8524, Recall=0.7206, binary_accuracy=0.9050, loss=0.2281, val_Precision=0.7604, val_Recall=0.5851, val_binary_accuracy=0.8469, val_loss=0.3399]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - Precision: 0.7874 - Recall: 0.5427 - binary_accuracy: 0.8308 - loss: 0.3869\n",
            "Testing on Fold #4/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [01:10<00:00,  1.13epoch/s, Precision=0.8763, Recall=0.7612, binary_accuracy=0.9187, loss=0.1972, val_Precision=0.7667, val_Recall=0.6328, val_binary_accuracy=0.8578, val_loss=0.3299]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Precision: 0.7777 - Recall: 0.6233 - binary_accuracy: 0.8570 - loss: 0.3373\n",
            "Testing on Fold #5/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [01:09<00:00,  1.14epoch/s, Precision=0.8465, Recall=0.7380, binary_accuracy=0.9069, loss=0.2201, val_Precision=0.7747, val_Recall=0.6333, val_binary_accuracy=0.8578, val_loss=0.3335]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Precision: 0.7956 - Recall: 0.6384 - binary_accuracy: 0.8627 - loss: 0.3028\n",
            "Performing k-fold cross-validation for the Angle Usefulness transformer ...\n",
            "Testing on Fold #1/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [01:02<00:00,  1.28epoch/s, Precision=0.8820, Recall=0.8272, binary_accuracy=0.9332, loss=0.1705, val_Precision=0.7401, val_Recall=0.6354, val_binary_accuracy=0.8438, val_loss=0.3655]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - Precision: 0.8115 - Recall: 0.7523 - binary_accuracy: 0.8921 - loss: 0.2715\n",
            "Testing on Fold #2/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [01:06<00:00,  1.20epoch/s, Precision=0.8690, Recall=0.8107, binary_accuracy=0.9268, loss=0.1724, val_Precision=0.7620, val_Recall=0.6513, val_binary_accuracy=0.8537, val_loss=0.3644]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - Precision: 0.7711 - Recall: 0.6852 - binary_accuracy: 0.8637 - loss: 0.3359\n",
            "Testing on Fold #3/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [00:58<00:00,  1.36epoch/s, Precision=0.8908, Recall=0.8248, binary_accuracy=0.9351, loss=0.1707, val_Precision=0.7654, val_Recall=0.6826, val_binary_accuracy=0.8655, val_loss=0.3314]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - Precision: 0.7676 - Recall: 0.6303 - binary_accuracy: 0.8428 - loss: 0.3733\n",
            "Testing on Fold #4/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [01:07<00:00,  1.18epoch/s, Precision=0.8775, Recall=0.8058, binary_accuracy=0.9280, loss=0.1762, val_Precision=0.8057, val_Recall=0.7094, val_binary_accuracy=0.8827, val_loss=0.2914]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - Precision: 0.8128 - Recall: 0.8042 - binary_accuracy: 0.9022 - loss: 0.2279"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - Precision: 0.8224 - Recall: 0.7639 - binary_accuracy: 0.8966 - loss: 0.2467\n",
            "Testing on Fold #5/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [01:04<00:00,  1.24epoch/s, Precision=0.8905, Recall=0.8268, binary_accuracy=0.9352, loss=0.1633, val_Precision=0.8589, val_Recall=0.7381, val_binary_accuracy=0.9013, val_loss=0.2540]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - Precision: 0.7101 - Recall: 0.6154 - binary_accuracy: 0.8315 - loss: 0.3780"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - Precision: 0.7585 - Recall: 0.6543 - binary_accuracy: 0.8553 - loss: 0.3410\n"
          ]
        }
      ],
      "source": [
        "epochs = 80\n",
        "for seq_module in ['gru', 'lstm', 'transformer']:\n",
        "    print(f'Performing k-fold cross-validation for the Angle Usefulness {seq_module} ...')\n",
        "    for test in range(k):\n",
        "        print(f'Testing on Fold #{test+1}/{k} ...')\n",
        "        X_train, X_test, y_train, y_test = split_by_fold(\n",
        "            processed_sequences,\n",
        "            numerical_labels,\n",
        "            folds,\n",
        "            test\n",
        "        )\n",
        "\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_train,\n",
        "            y_train,\n",
        "            test_size=0.2,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        y_train = np.array(y_train, dtype=np.int32)\n",
        "        y_test = np.array(y_test, dtype=np.int32)\n",
        "        y_val = np.array(y_val, dtype=np.int32)\n",
        "\n",
        "        Y_train = np.empty((len(X_train), len(X_train[0][0])), np.float32)\n",
        "        Y_val = np.empty((len(X_val), len(X_train[0][0])), np.float32)\n",
        "        Y_test = np.empty((len(X_test), len(X_train[0][0])), np.float32)\n",
        "\n",
        "        for (Y, y) in [(Y_train, y_train), (Y_val, y_val), (Y_test, y_test)]:\n",
        "            for i in range(Y.shape[0]):\n",
        "                for angle in range(Y.shape[1]):\n",
        "                    if angle in label_angles[y[i]]:\n",
        "                        Y[i, angle] = 1\n",
        "                    else:\n",
        "                        Y[i, angle] = 0\n",
        "\n",
        "        usefulness_model = angle_usefulness_model(num_angles=len(X_train[0][0]), maxlen=MAXLEN, module=seq_module, lr=1e-3)\n",
        "\n",
        "        pbar_callback = TQDMProgressBar(epochs=epochs)\n",
        "\n",
        "        callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "            MODEL_SAVE_PATH_USEFULNESS,\n",
        "            monitor=\"val_binary_accuracy\",\n",
        "            verbose=0,\n",
        "            save_best_only=True,\n",
        "            save_weights_only=True,\n",
        "            mode=\"max\",\n",
        "            save_freq=\"epoch\",\n",
        "            initial_value_threshold=None,\n",
        "        )\n",
        "\n",
        "        train_ds = UsefulnessDataset(X_train, Y_train, y_train, batch_size=batch_size, maxlen=MAXLEN, train=True)\n",
        "        val_ds = UsefulnessDataset(X_val, Y_val, y_val, batch_size=min(batch_size, len(X_val)), maxlen=MAXLEN, train=False)\n",
        "\n",
        "        history = usefulness_model.fit(\n",
        "            train_ds,\n",
        "            validation_data=val_ds,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            callbacks=[callback, pbar_callback],\n",
        "            verbose=0, # Change this to 1 if you want progressive display while training\n",
        "        )\n",
        "\n",
        "        # Load the trained classifier model\n",
        "        usefulness_model.load_weights(\n",
        "            MODEL_SAVE_PATH_USEFULNESS\n",
        "        )\n",
        "\n",
        "        test_ds = UsefulnessDataset(X_test, Y_test, y_test, batch_size=batch_size, maxlen=MAXLEN, train=False)\n",
        "        usefulness_model.evaluate(test_ds, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8tPsAjN_JAe",
        "outputId": "dad2a042-6645-41d5-cfad-4e5bedb98572"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing k-fold cross-validation for the Siamese gru ...\n",
            "Testing on Fold #1/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 60/60 [06:57<00:00,  6.97s/epoch, Precision=0.8665, Recall=0.7572, binary_accuracy=0.9159, loss=0.2037, val_Precision=0.7912, val_Recall=0.6530, val_binary_accuracy=0.8732, val_loss=0.3136]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[1m   1/4562\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:50\u001b[0m 51ms/step - Precision: 0.8025 - Recall: 0.7065 - binary_accuracy: 0.8832 - loss: 0.3148"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4562/4562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 33ms/step - Precision: 0.7955 - Recall: 0.6748 - binary_accuracy: 0.8803 - loss: 0.3130\n",
            "Testing on Fold #2/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 60/60 [06:54<00:00,  6.90s/epoch, Precision=0.8631, Recall=0.7600, binary_accuracy=0.9151, loss=0.2022, val_Precision=0.7870, val_Recall=0.7032, val_binary_accuracy=0.8824, val_loss=0.2890]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[1m   1/4562\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:45\u001b[0m 49ms/step - Precision: 0.8027 - Recall: 0.6448 - binary_accuracy: 0.8723 - loss: 0.2624"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4562/4562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 35ms/step - Precision: 0.7713 - Recall: 0.6622 - binary_accuracy: 0.8737 - loss: 0.3182\n",
            "Testing on Fold #3/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 60/60 [07:01<00:00,  7.03s/epoch, Precision=0.8441, Recall=0.7151, binary_accuracy=0.9015, loss=0.2378, val_Precision=0.7883, val_Recall=0.6543, val_binary_accuracy=0.8753, val_loss=0.2875]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[1m   1/4562\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:11\u001b[0m 55ms/step - Precision: 0.8028 - Recall: 0.6230 - binary_accuracy: 0.8682 - loss: 0.2908"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4562/4562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 35ms/step - Precision: 0.7858 - Recall: 0.6701 - binary_accuracy: 0.8784 - loss: 0.2958\n",
            "Testing on Fold #4/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 60/60 [07:07<00:00,  7.12s/epoch, Precision=0.8450, Recall=0.7322, binary_accuracy=0.9058, loss=0.2290, val_Precision=0.7442, val_Recall=0.6172, val_binary_accuracy=0.8575, val_loss=0.3423]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[1m   1/4562\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:42\u001b[0m 49ms/step - Precision: 0.8357 - Recall: 0.6763 - binary_accuracy: 0.8927 - loss: 0.2507"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4562/4562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 37ms/step - Precision: 0.7372 - Recall: 0.6162 - binary_accuracy: 0.8575 - loss: 0.3828\n",
            "Testing on Fold #5/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 60/60 [06:52<00:00,  6.88s/epoch, Precision=0.8637, Recall=0.7485, binary_accuracy=0.9133, loss=0.2058, val_Precision=0.7378, val_Recall=0.6744, val_binary_accuracy=0.8679, val_loss=0.3302]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[1m   1/4468\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:02\u001b[0m 54ms/step - Precision: 0.7143 - Recall: 0.5497 - binary_accuracy: 0.8261 - loss: 0.3471"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4468/4468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 39ms/step - Precision: 0.7628 - Recall: 0.6102 - binary_accuracy: 0.8636 - loss: 0.3284\n",
            "Performing k-fold cross-validation for the Siamese lstm ...\n",
            "Testing on Fold #1/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 60/60 [06:53<00:00,  6.89s/epoch, Precision=0.8755, Recall=0.7773, binary_accuracy=0.9216, loss=0.1913, val_Precision=0.7935, val_Recall=0.6705, val_binary_accuracy=0.8767, val_loss=0.3205]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4562/4562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 36ms/step - Precision: 0.8108 - Recall: 0.7154 - binary_accuracy: 0.8914 - loss: 0.2689\n",
            "Testing on Fold #2/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 60/60 [07:07<00:00,  7.12s/epoch, Precision=0.8814, Recall=0.7884, binary_accuracy=0.9256, loss=0.1805, val_Precision=0.8124, val_Recall=0.7055, val_binary_accuracy=0.8899, val_loss=0.3237]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m   1/4562\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:18\u001b[0m 57ms/step - Precision: 0.8917 - Recall: 0.7292 - binary_accuracy: 0.9062 - loss: 0.2086"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4562/4562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 39ms/step - Precision: 0.6529 - Recall: 0.5737 - binary_accuracy: 0.8276 - loss: 0.5436\n",
            "Testing on Fold #3/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 60/60 [07:14<00:00,  7.24s/epoch, Precision=0.8708, Recall=0.7732, binary_accuracy=0.9198, loss=0.1887, val_Precision=0.7974, val_Recall=0.7193, val_binary_accuracy=0.8876, val_loss=0.2956]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4562/4562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 36ms/step - Precision: 0.7692 - Recall: 0.6986 - binary_accuracy: 0.8791 - loss: 0.3973\n",
            "Testing on Fold #4/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress:  85%|████████▌ | 51/60 [05:52<01:01,  6.87s/epoch, Precision=0.8679, Recall=0.7702, binary_accuracy=0.9183, loss=0.1996, val_Precision=0.7665, val_Recall=0.6535, val_binary_accuracy=0.8676, val_loss=0.3379]"
          ]
        }
      ],
      "source": [
        "epochs = 60\n",
        "for seq_module in ['gru', 'lstm', 'transformer']:\n",
        "    print(f'Performing k-fold cross-validation for the Siamese {seq_module} ...')\n",
        "    for test in range(k):\n",
        "        print(f'Testing on Fold #{test+1}/{k} ...')\n",
        "        X_train, X_test, y_train, y_test = split_by_fold(\n",
        "            processed_sequences,\n",
        "            numerical_labels,\n",
        "            folds,\n",
        "            test\n",
        "        )\n",
        "\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_train,\n",
        "            y_train,\n",
        "            test_size=0.2,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        y_train = np.array(y_train, dtype=np.int32)\n",
        "        y_test = np.array(y_test, dtype=np.int32)\n",
        "        y_val = np.array(y_val, dtype=np.int32)\n",
        "\n",
        "        train_batches = 10 * len(X_train) // batch_size\n",
        "        val_batches = 10 * len(X_val) // batch_size\n",
        "        train_ds = SimilarityDataset(X_train, y_train, num_batches=train_batches, batch_size=batch_size, label_angles=label_angles, maxlen=MAXLEN, train=True)\n",
        "        val_ds = SimilarityDataset(X_val, y_val, num_batches=val_batches, batch_size=batch_size, label_angles=label_angles, maxlen=MAXLEN, train=False)\n",
        "\n",
        "        callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "            MODEL_SAVE_PATH_SIMILARITY,\n",
        "            monitor=\"val_binary_accuracy\",\n",
        "            verbose=0,\n",
        "            save_best_only=True,\n",
        "            save_weights_only=True,\n",
        "            mode=\"max\",\n",
        "            save_freq=\"epoch\",\n",
        "            initial_value_threshold=None,\n",
        "        )\n",
        "\n",
        "        pbar_callback = TQDMProgressBar(epochs=epochs)\n",
        "\n",
        "        # Build and train Siamese model\n",
        "        similarity_model = angle_similarity_model(num_angles=len(X_train[0][0]), maxlen=MAXLEN, module=seq_module, lr=1e-3)\n",
        "        history = similarity_model.fit(\n",
        "            train_ds,\n",
        "            validation_data=val_ds,\n",
        "            epochs=epochs,\n",
        "            callbacks=[callback, pbar_callback],\n",
        "            verbose=0,  # Change this to 1 if you want progressive display while training\n",
        "        )\n",
        "\n",
        "        similarity_model.load_weights(\n",
        "            MODEL_SAVE_PATH_SIMILARITY,\n",
        "        )\n",
        "\n",
        "        # Make a large dataset in terms of pair in order to have a more reliable test\n",
        "        # since we can't test on all possible pairs (very huge number)\n",
        "        test_batches = 1000 * len(X_test) // batch_size\n",
        "        # Evaluate the Siamese model on the test set\n",
        "        test_ds = SimilarityDataset(X_test, y_test, num_batches=test_batches, batch_size=batch_size, label_angles=label_angles, maxlen=MAXLEN, train=False)\n",
        "        similarity_model.evaluate(test_ds, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ncJ_OCo_1ej"
      },
      "source": [
        "# One-shot Generalization Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3UuYgIW_0kd"
      },
      "outputs": [],
      "source": [
        "tests = [[3, 4, 13, 14, 15, 17], [1, 3, 4, 13, 14, 20], [1, 3, 6, 13, 19, 20], [1, 3, 7, 13, 14, 16], [1, 3, 5, 13, 14, 19], [1, 2, 3, 13, 19, 21], [0, 3, 6, 7, 13, 19], [1, 3, 4, 13, 14, 21], [3, 7, 13, 14, 16, 17], [1, 3, 10, 13, 20, 21]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJar4K7_ADxQ"
      },
      "outputs": [],
      "source": [
        "# Function to split data by specifying test labels\n",
        "def split_by_labels(data_x, data_y, test_labels):\n",
        "    X_train, X_test, y_train, y_test = [], [], [], []\n",
        "    for sample_x, sample_y in zip(data_x, data_y):\n",
        "        if sample_y in test_labels:\n",
        "            X_test.append(sample_x)\n",
        "            y_test.append(sample_y)\n",
        "        else:\n",
        "            X_train.append(sample_x)\n",
        "            y_train.append(sample_y)\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwMU3IQgAq5-"
      },
      "outputs": [],
      "source": [
        "epochs = 80\n",
        "print('Performing one-shot validation for the Angle Usefulness Transformer ...')\n",
        "for test in tests:\n",
        "    print(f'Testing on Exercises: {test} ...')\n",
        "    X_train, X_test, y_train, y_test = split_by_labels(\n",
        "        processed_sequences,\n",
        "        numerical_labels,\n",
        "        test_labels=test,\n",
        "    )\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        test_size=0.2,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    y_train = np.array(y_train, dtype=np.int32)\n",
        "    y_test = np.array(y_test, dtype=np.int32)\n",
        "    y_val = np.array(y_val, dtype=np.int32)\n",
        "\n",
        "    Y_train = np.empty((len(X_train), len(X_train[0][0])), np.float32)\n",
        "    Y_val = np.empty((len(X_val), len(X_train[0][0])), np.float32)\n",
        "    Y_test = np.empty((len(X_test), len(X_train[0][0])), np.float32)\n",
        "\n",
        "    for (Y, y) in [(Y_train, y_train), (Y_val, y_val), (Y_test, y_test)]:\n",
        "        for i in range(Y.shape[0]):\n",
        "            for angle in range(Y.shape[1]):\n",
        "                if angle in label_angles[y[i]]:\n",
        "                    Y[i, angle] = 1\n",
        "                else:\n",
        "                    Y[i, angle] = 0\n",
        "\n",
        "    usefulness_model = angle_usefulness_model(maxlen=MAXLEN, module='transformer', lr=1e-4)\n",
        "\n",
        "    callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        MODEL_SAVE_PATH_USEFULNESS,\n",
        "        monitor=\"val_binary_accuracy\",\n",
        "        verbose=0,\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "        mode=\"max\",\n",
        "        save_freq=\"epoch\",\n",
        "        initial_value_threshold=None,\n",
        "    )\n",
        "\n",
        "    pbar_callback = TQDMProgressBar(epochs=epochs)\n",
        "\n",
        "    train_ds = UsefulnessDataset(X_train, Y_train, y_train, batch_size=batch_size, maxlen=MAXLEN, train=True)\n",
        "    val_ds = UsefulnessDataset(X_val, Y_val, y_val, batch_size=min(batch_size, len(X_val)), maxlen=MAXLEN, train=False)\n",
        "\n",
        "    history = usefulness_model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        callbacks=[callback, pbar_callback],\n",
        "        verbose=0,  # Change this to 1 if you want progressive display while training\n",
        "    )\n",
        "\n",
        "    # Load the trained classifier model\n",
        "    usefulness_model.load_weights(\n",
        "        MODEL_SAVE_PATH_USEFULNESS\n",
        "    )\n",
        "\n",
        "    test_ds = UsefulnessDataset(X_test, Y_test, y_test, batch_size=batch_size, maxlen=MAXLEN, train=False)\n",
        "    usefulness_model.evaluate(test_ds, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFhxjwVJARTw"
      },
      "outputs": [],
      "source": [
        "epochs = 60\n",
        "print('Performing one-shot validation for the Siamese Transformer ...')\n",
        "for test in tests:\n",
        "    print(f'Testing on Exercises: {test} ...')\n",
        "\n",
        "    X_train, X_test, y_train, y_test = split_by_labels(\n",
        "        processed_sequences,\n",
        "        numerical_labels,\n",
        "        test_labels=test,\n",
        "    )\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        test_size=0.2,\n",
        "        random_state=42\n",
        "    )\n",
        "    train_batches = 10 * len(X_train) // batch_size\n",
        "    val_batches = 10 * len(X_val) // batch_size\n",
        "    train_ds = SimilarityDataset(X_train, y_train, num_batches=train_batches, batch_size=batch_size, label_angles=label_angles, maxlen=MAXLEN, train=True)\n",
        "    val_ds = SimilarityDataset(X_val, y_val, num_batches=val_batches, batch_size=batch_size, label_angles=label_angles, maxlen=MAXLEN, train=False)\n",
        "\n",
        "    callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        MODEL_SAVE_PATH_SIMILARITY,\n",
        "        monitor=\"val_binary_accuracy\",\n",
        "        verbose=0,\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "        mode=\"max\",\n",
        "        save_freq=\"epoch\",\n",
        "        initial_value_threshold=None,\n",
        "    )\n",
        "\n",
        "    pbar_callback = TQDMProgressBar(epochs=epochs)\n",
        "\n",
        "    # Build and train Siamese model\n",
        "    similarity_model = angle_similarity_model(maxlen=MAXLEN, module='transformer', lr=1e-3)\n",
        "    history = similarity_model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=epochs,\n",
        "        callbacks=[callback, pbar_callback],\n",
        "        verbose=0,  # Change this to 1 if you want progressive display while training\n",
        "    )\n",
        "\n",
        "    # Load the trained Siamese model\n",
        "    similarity_model.load_weights(\n",
        "        MODEL_SAVE_PATH_SIMILARITY,\n",
        "    )\n",
        "\n",
        "    # Make a large dataset in terms of pair in order to have a more reliable test\n",
        "    # since we can't test on all possible pairs (very huge number)\n",
        "    test_batches = 1000 * len(X_test) // batch_size\n",
        "    # Evaluate the Siamese model on the test set\n",
        "    test_ds = SimilarityDataset(X_test, y_test, num_batches=test_batches, batch_size=batch_size, label_angles=label_angles, maxlen=MAXLEN, train=False)\n",
        "    similarity_model.evaluate(test_ds, verbose=1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}