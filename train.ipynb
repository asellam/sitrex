{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_HAe5VzbUd7"
      },
      "source": [
        "# Get the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA7POIpDbUd8",
        "outputId": "f8bb6204-90b2-4f81-e7c1-1ef244a4e776"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'sitrex' already exists and is not an empty directory.\n",
            "/content/sitrex\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/asellam/sitrex.git\n",
        "%cd sitrex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTceCwapbUd_",
        "outputId": "4c01ede5-c904-4517-ef16-be2dedc529f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.12 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.12.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.23 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.15.3)\n",
            "Requirement already satisfied: tqdm>=4.65 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (1.6.1)\n",
            "Requirement already satisfied: kagglehub>=0.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (0.3.12)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12->-r requirements.txt (line 2)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12->-r requirements.txt (line 2)) (25.2.10)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12->-r requirements.txt (line 2)) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12->-r requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12->-r requirements.txt (line 2)) (1.74.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12->-r requirements.txt (line 2)) (3.14.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12->-r requirements.txt (line 2)) (0.4.30)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12->-r requirements.txt (line 2)) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12->-r requirements.txt (line 2)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12->-r requirements.txt (line 2)) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12->-r requirements.txt (line 2)) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12->-r requirements.txt (line 2)) (4.25.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12->-r requirements.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12->-r requirements.txt (line 2)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12->-r requirements.txt (line 2)) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12->-r requirements.txt (line 2)) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12->-r requirements.txt (line 2)) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12->-r requirements.txt (line 2)) (4.14.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12->-r requirements.txt (line 2)) (1.14.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12->-r requirements.txt (line 2)) (0.37.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2->-r requirements.txt (line 12)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2->-r requirements.txt (line 12)) (3.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub>=0.2->-r requirements.txt (line 15)) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub>=0.2->-r requirements.txt (line 15)) (2.32.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12->-r requirements.txt (line 2)) (0.45.1)\n",
            "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12->-r requirements.txt (line 2)) (0.4.30)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12->-r requirements.txt (line 2)) (0.5.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12->-r requirements.txt (line 2)) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12->-r requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12->-r requirements.txt (line 2)) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12->-r requirements.txt (line 2)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12->-r requirements.txt (line 2)) (3.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub>=0.2->-r requirements.txt (line 15)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub>=0.2->-r requirements.txt (line 15)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub>=0.2->-r requirements.txt (line 15)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub>=0.2->-r requirements.txt (line 15)) (2025.8.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12->-r requirements.txt (line 2)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12->-r requirements.txt (line 2)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12->-r requirements.txt (line 2)) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12->-r requirements.txt (line 2)) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12->-r requirements.txt (line 2)) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12->-r requirements.txt (line 2)) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12->-r requirements.txt (line 2)) (3.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6fubIm76ZdW"
      },
      "source": [
        "# Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZZt0APPizmv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b01e5598-bd9a-4987-98fa-fcd5980f4a8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/abdellah213/sitrex-dataset?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 418M/418M [00:03<00:00, 133MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download('abdellah213/sitrex-dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbuBNCCw69KI"
      },
      "source": [
        "# Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p0IEFaNKzz3F"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sitrex.preprocessing import load_dataset, preprocess_data, SimilarityDataset, UsefulnessDataset\n",
        "from sitrex.model import angle_usefulness_model, angle_similarity_model, TQDMProgressBar\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "# Define constants\n",
        "DATASET_PATH = os.path.join(path, 'dataset')\n",
        "# EarlyStop save path for the Siamese Transformer\n",
        "MODEL_SAVE_PATH_SIMILARITY = './angle_similarity_model.keras'\n",
        "# EarlyStop save path for the Angle Usefulness Transformer\n",
        "MODEL_SAVE_PATH_USEFULNESS = './angle_usefulness_model.keras'\n",
        "# Maximum sequence length (L)\n",
        "MAXLEN = 100\n",
        "# Batch Size\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELxuOym7bUeA"
      },
      "source": [
        "# Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMNQw9Ql7_YW",
        "outputId": "4e55b33c-b29f-403c-b4ed-ab322944da5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dataset: 100%|██████████| 727/727 [04:32<00:00,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 727 sequences with labels.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "all_sequences, labels, exercise_angles = load_dataset(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8Fvh4Ak7Hnw"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "C3XNnuaE8P0H"
      },
      "outputs": [],
      "source": [
        "processed_sequences, numerical_labels, label_angles = preprocess_data(all_sequences, labels, exercise_angles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1-x8hJi8Wxz"
      },
      "source": [
        "# Tensorflow Dataset and Model Routines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAfoMcUK9ceH"
      },
      "source": [
        "# K-Fold Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "45B5HZpO9Vl9"
      },
      "outputs": [],
      "source": [
        "def split_by_fold(data_x, data_y, folds, test):\n",
        "    train_x, test_x, train_y, test_y = [], [], [], []\n",
        "    for fold, split in enumerate(folds):\n",
        "        for sample in split:\n",
        "            if fold == test:\n",
        "                test_x.append(data_x[sample])\n",
        "                test_y.append(data_y[sample])\n",
        "            else:\n",
        "                train_x.append(data_x[sample])\n",
        "                train_y.append(data_y[sample])\n",
        "    return train_x, test_x, train_y, test_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOFTlTJZ9wRL",
        "outputId": "bf197c6c-8e50-43a6-a3ff-36995dbc66b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([513, 693, 377,  33,  63, 467, 346, 511, 148, 388, 174,  65, 469,\n",
            "       428, 707, 350, 210,  72, 449,  78,  54,  39,  97, 211,  81, 557,\n",
            "       629, 443, 514,  10, 361, 319, 676, 673, 231, 363, 158, 462, 296,\n",
            "       578, 723, 396,  86, 329, 597, 235, 351, 568, 299, 685, 165, 571,\n",
            "       164, 223, 539, 399, 281, 227, 714, 620, 199, 705, 155,  49, 332,\n",
            "       101, 477, 234, 437, 196,  23, 266,  77, 212, 198, 109, 713, 327,\n",
            "       528, 336, 209,  30, 602, 674, 480, 554, 393, 547, 118, 609, 133,\n",
            "       688,  84,  79, 213, 433, 448, 181,  31, 254, 598, 215, 412, 591,\n",
            "       275,  55, 679, 594, 691, 300,  76,   2, 506, 464, 192,  60, 722,\n",
            "       120, 362, 429, 314, 218, 220, 634, 260, 405, 244, 426, 431,  90,\n",
            "       331, 538,  69, 204, 131,  44,  70, 349, 717, 569, 135, 601, 239,\n",
            "       579, 642, 432]), array([136, 286,   6, 657, 587, 334, 250, 145, 338, 132, 306, 660,  41,\n",
            "       108, 292,  56, 417, 690, 333, 537,  24, 404, 465, 666, 311, 457,\n",
            "       110,  82,  51, 394, 582, 497, 290, 265, 501, 650, 603,  18, 342,\n",
            "       369, 694,  83,  61, 533, 625,  29, 584, 710, 678, 367, 182, 482,\n",
            "       604, 408, 585, 381, 208, 264, 436, 589, 176, 294, 259, 530, 248,\n",
            "       137, 409, 680, 163, 425, 637, 483, 581, 324, 328, 450, 104, 114,\n",
            "       652, 575, 651, 424,  92,   7,  89, 551, 356, 479, 544, 515, 453,\n",
            "       247, 140,  28,  43,  42,  73, 167, 398, 635,  66,  11, 335, 627,\n",
            "       178, 645, 456, 446, 355, 526, 177, 622, 628, 257, 291,  15, 422,\n",
            "       256, 302, 318, 623, 451, 340, 430, 375,   9, 249,  22, 221, 655,\n",
            "       711, 687, 607, 203, 440,  93, 326, 535, 416, 284, 184, 586, 323,\n",
            "       153,  75, 371]), array([277,  68, 420, 188, 271, 236,  88, 615, 117, 125, 596, 289, 238,\n",
            "         0, 718, 344, 632, 380, 278, 116, 228, 633, 357, 274, 487, 144,\n",
            "       423, 542, 656, 529, 268, 512, 307, 310,  46, 261, 195, 726, 608,\n",
            "       107, 507, 543, 360, 100, 390, 649, 527, 704, 179, 304, 352, 658,\n",
            "       698, 149, 124, 599, 630, 185, 708, 725, 382, 716, 500, 321, 353,\n",
            "       669, 142, 141, 434, 320,  19, 172, 590, 312, 675,  12, 305, 354,\n",
            "        25, 541, 169,  38, 445, 245, 298, 478, 272, 154, 126, 516, 341,\n",
            "       287, 113, 485, 173, 359, 395,  57, 519, 222, 280,  17, 447, 322,\n",
            "       255, 699, 696, 190, 595, 641, 411,  94, 180, 301, 470, 534, 665,\n",
            "       558, 640, 473,   5, 712,  45, 439, 548, 171,  16,  48, 702, 664,\n",
            "         3, 494, 667, 316, 668, 283,  96, 285, 481, 225,  26, 570, 263,\n",
            "        50, 364, 229]), array([ 37, 157, 237, 697, 374, 370, 442, 175, 616, 127, 536, 194, 618,\n",
            "       626, 468, 490, 493, 701, 605, 624,  67, 486, 168, 444, 639, 162,\n",
            "       309, 193, 518, 365, 383, 654, 525, 152, 495, 517, 522, 226, 606,\n",
            "       580, 103, 421, 419, 567, 550,  74, 115, 407, 721, 119,  53, 151,\n",
            "       403, 683, 207, 503, 521, 611, 695,   8, 588,  36, 452, 139, 253,\n",
            "       303, 610, 549, 368,  59, 499, 684, 111, 523, 531, 262, 297, 414,\n",
            "       150, 576, 644, 488, 147, 146, 532, 672, 545, 348, 463, 325, 186,\n",
            "       123, 617, 143, 692, 197, 279, 293, 400, 122, 183, 202, 438, 246,\n",
            "       415, 643, 129, 402, 572, 671, 219, 659, 552, 662, 559, 386, 703,\n",
            "       509, 267, 441, 496, 112, 232, 631, 373, 233, 583, 317, 410, 648,\n",
            "       358, 258, 282, 376, 384, 224, 689, 593, 472, 347, 505, 715, 670,\n",
            "       653, 619, 612]), array([556, 577,  85, 242, 159, 524,  35, 540, 170, 621, 613, 682,  95,\n",
            "       563, 240, 574, 460, 553, 636, 206, 392, 397, 719, 217,   4, 647,\n",
            "       546,  98, 573, 406, 502,  47,  32, 200, 134,  27, 638, 230, 489,\n",
            "       378, 288, 418, 391, 592, 498, 138,  62, 471, 128, 706, 520,  64,\n",
            "        14, 156,  40, 492, 379, 187, 216,  52, 337, 295, 251, 461, 455,\n",
            "       724, 269, 201, 161, 555, 401, 476, 105, 565, 389,   1, 677, 561,\n",
            "        80, 205,  34, 508, 427, 454, 366,  91, 339, 564, 345, 241,  13,\n",
            "       315, 600, 387, 273, 166, 720, 646, 484, 709, 504, 243, 566, 562,\n",
            "       686, 189, 475, 681, 510,  58, 474, 560, 252,  21, 313, 459, 160,\n",
            "       276, 191, 385, 413, 491, 343, 308, 661, 130, 663,  99, 372,  87,\n",
            "       458, 330, 214, 466, 121, 614,  20, 700,  71, 106, 270, 435, 102])]\n"
          ]
        }
      ],
      "source": [
        "# Preparing the 5 folds\n",
        "k = 5\n",
        "N = len(numerical_labels)\n",
        "indexes = np.arange(N)\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(indexes)\n",
        "\n",
        "fold_size = int(np.ceil(N / k))\n",
        "\n",
        "folds = []\n",
        "for i in range(k):\n",
        "    start = i * fold_size\n",
        "    end = min(start + fold_size, N)\n",
        "    folds.append(indexes[start:end])\n",
        "\n",
        "print(folds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCF9f-Il-Bv4",
        "outputId": "ed9d93c9-a6c5-4c08-c58f-d1ed1278e46a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing k-fold cross-validation for the Angle Usefulness gru ...\n",
            "Testing on Fold #1/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [03:29<00:00,  2.62s/epoch, loss=0.1861, binary_accuracy=0.9259, precision=0.8677, recall=0.8081, val_loss=0.3080, val_binary_accuracy=0.8637, val_precision=0.7800, val_recall=0.6649]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 23ms/step - loss: 0.2635 - binary_accuracy: 0.8910 - precision: 0.8116 - recall: 0.7382\n",
            "Testing on Fold #2/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [03:33<00:00,  2.67s/epoch, loss=0.1687, binary_accuracy=0.9310, precision=0.8851, recall=0.8125, val_loss=0.2144, val_binary_accuracy=0.9049, val_precision=0.8485, val_recall=0.7491]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 24ms/step - loss: 0.2917 - binary_accuracy: 0.8733 - precision: 0.8277 - recall: 0.6590\n",
            "Testing on Fold #3/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [03:36<00:00,  2.70s/epoch, loss=0.1936, binary_accuracy=0.9203, precision=0.8635, recall=0.7857, val_loss=0.3059, val_binary_accuracy=0.8714, val_precision=0.7882, val_recall=0.6955]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 19ms/step - loss: 0.2814 - binary_accuracy: 0.8706 - precision: 0.8270 - recall: 0.6570\n",
            "Testing on Fold #4/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [03:07<00:00,  2.34s/epoch, loss=0.1773, binary_accuracy=0.9279, precision=0.8709, recall=0.8142, val_loss=0.3015, val_binary_accuracy=0.8804, val_precision=0.8246, val_recall=0.6980]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 28ms/step - loss: 0.3344 - binary_accuracy: 0.8560 - precision: 0.7953 - recall: 0.6373\n",
            "Testing on Fold #5/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [03:25<00:00,  2.57s/epoch, loss=0.1999, binary_accuracy=0.9162, precision=0.8642, recall=0.7634, val_loss=0.2825, val_binary_accuracy=0.8800, val_precision=0.8077, val_recall=0.6835]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 20ms/step - loss: 0.2804 - binary_accuracy: 0.8750 - precision: 0.8053 - recall: 0.6803\n",
            "Performing k-fold cross-validation for the Angle Usefulness lstm ...\n",
            "Testing on Fold #1/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [03:48<00:00,  2.86s/epoch, loss=0.1737, binary_accuracy=0.9284, precision=0.8776, recall=0.8082, val_loss=0.2578, val_binary_accuracy=0.8909, val_precision=0.8425, val_recall=0.7153]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 21ms/step - loss: 0.2751 - binary_accuracy: 0.8648 - precision: 0.7587 - recall: 0.6788\n",
            "Testing on Fold #2/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [03:37<00:00,  2.71s/epoch, loss=0.1907, binary_accuracy=0.9211, precision=0.8696, recall=0.7819, val_loss=0.2718, val_binary_accuracy=0.8872, val_precision=0.8100, val_recall=0.7106]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 30ms/step - loss: 0.3071 - binary_accuracy: 0.8706 - precision: 0.8364 - recall: 0.6359\n",
            "Testing on Fold #3/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [03:48<00:00,  2.85s/epoch, loss=0.1675, binary_accuracy=0.9335, precision=0.8898, recall=0.8188, val_loss=0.2500, val_binary_accuracy=0.8868, val_precision=0.8130, val_recall=0.7370]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 28ms/step - loss: 0.2557 - binary_accuracy: 0.8804 - precision: 0.8276 - recall: 0.7024\n",
            "Testing on Fold #4/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [03:35<00:00,  2.69s/epoch, loss=0.1655, binary_accuracy=0.9346, precision=0.8887, recall=0.8246, val_loss=0.2691, val_binary_accuracy=0.8818, val_precision=0.8060, val_recall=0.7304]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 32ms/step - loss: 0.3443 - binary_accuracy: 0.8563 - precision: 0.8111 - recall: 0.6186\n",
            "Testing on Fold #5/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [03:51<00:00,  2.90s/epoch, loss=0.1747, binary_accuracy=0.9303, precision=0.8904, recall=0.8027, val_loss=0.2725, val_binary_accuracy=0.9072, val_precision=0.8494, val_recall=0.7649]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 32ms/step - loss: 0.2854 - binary_accuracy: 0.8801 - precision: 0.7903 - recall: 0.7289\n",
            "Performing k-fold cross-validation for the Angle Usefulness transformer ...\n",
            "Testing on Fold #1/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [06:07<00:00,  4.59s/epoch, loss=0.1516, binary_accuracy=0.9403, precision=0.8859, recall=0.8566, val_loss=0.2808, val_binary_accuracy=0.8931, val_precision=0.8307, val_recall=0.7413]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 42ms/step - loss: 0.2443 - binary_accuracy: 0.9005 - precision: 0.8265 - recall: 0.7652\n",
            "Testing on Fold #2/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [06:16<00:00,  4.70s/epoch, loss=0.1486, binary_accuracy=0.9384, precision=0.8872, recall=0.8459, val_loss=0.2638, val_binary_accuracy=0.8986, val_precision=0.8061, val_recall=0.7766]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3113 - binary_accuracy: 0.8845 - precision: 0.8152 - recall: 0.7295\n",
            "Testing on Fold #3/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [05:40<00:00,  4.26s/epoch, loss=0.1529, binary_accuracy=0.9371, precision=0.8880, recall=0.8384, val_loss=0.2348, val_binary_accuracy=0.9126, val_precision=0.8571, val_recall=0.7993]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 39ms/step - loss: 0.2330 - binary_accuracy: 0.9046 - precision: 0.8546 - recall: 0.7781\n",
            "Testing on Fold #4/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [05:30<00:00,  4.14s/epoch, loss=0.1325, binary_accuracy=0.9487, precision=0.9054, recall=0.8730, val_loss=0.2709, val_binary_accuracy=0.8976, val_precision=0.8371, val_recall=0.7628]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 44ms/step - loss: 0.2894 - binary_accuracy: 0.8801 - precision: 0.8096 - recall: 0.7342\n",
            "Testing on Fold #5/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 80/80 [06:15<00:00,  4.69s/epoch, loss=0.1385, binary_accuracy=0.9465, precision=0.9051, recall=0.8627, val_loss=0.2062, val_binary_accuracy=0.9108, val_precision=0.8490, val_recall=0.7830]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 40ms/step - loss: 0.2510 - binary_accuracy: 0.8947 - precision: 0.7915 - recall: 0.8039\n"
          ]
        }
      ],
      "source": [
        "for seq_module in ['gru', 'lstm', 'transformer']:\n",
        "    print(f'Performing k-fold cross-validation for the Angle Usefulness {seq_module} ...')\n",
        "    for test in range(k):\n",
        "        print(f'Testing on Fold #{test+1}/{k} ...')\n",
        "        X_train, X_test, y_train, y_test = split_by_fold(\n",
        "            processed_sequences,\n",
        "            numerical_labels,\n",
        "            folds,\n",
        "            test\n",
        "        )\n",
        "\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_train,\n",
        "            y_train,\n",
        "            test_size=0.2,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        y_train = np.array(y_train, dtype=np.int32)\n",
        "        y_test = np.array(y_test, dtype=np.int32)\n",
        "        y_val = np.array(y_val, dtype=np.int32)\n",
        "\n",
        "        Y_train = np.empty((len(X_train), len(X_train[0][0])), np.float32)\n",
        "        Y_val = np.empty((len(X_val), len(X_train[0][0])), np.float32)\n",
        "        Y_test = np.empty((len(X_test), len(X_train[0][0])), np.float32)\n",
        "\n",
        "        for (Y, y) in [(Y_train, y_train), (Y_val, y_val), (Y_test, y_test)]:\n",
        "            for i in range(Y.shape[0]):\n",
        "                for angle in range(Y.shape[1]):\n",
        "                    if angle in label_angles[y[i]]:\n",
        "                        Y[i, angle] = 1\n",
        "                    else:\n",
        "                        Y[i, angle] = 0\n",
        "\n",
        "        usefulness_model = angle_usefulness_model(maxlen=MAXLEN, module=seq_module, lr=1e-3)\n",
        "\n",
        "        pbar_callback = TQDMProgressBar(epochs=80)\n",
        "\n",
        "        callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "            MODEL_SAVE_PATH_USEFULNESS,\n",
        "            monitor=\"val_binary_accuracy\",\n",
        "            verbose=0,\n",
        "            save_best_only=True,\n",
        "            save_weights_only=False,\n",
        "            mode=\"max\",\n",
        "            save_freq=\"epoch\",\n",
        "            initial_value_threshold=None,\n",
        "        )\n",
        "\n",
        "        train_ds = UsefulnessDataset(X_train, Y_train, y_train, batch_size=batch_size, maxlen=MAXLEN, train=True)\n",
        "        val_ds = UsefulnessDataset(X_val, Y_val, y_val, batch_size=min(batch_size, len(X_val)), maxlen=MAXLEN, train=False)\n",
        "\n",
        "        history = usefulness_model.fit(\n",
        "            train_ds,\n",
        "            validation_data=val_ds,\n",
        "            batch_size=batch_size,\n",
        "            epochs=80,\n",
        "            callbacks=[callback, pbar_callback],\n",
        "            verbose=0, # Change this to 1 if you want progressive display while training\n",
        "        )\n",
        "\n",
        "        # Load the trained classifier model\n",
        "        usefulness_model = tf.keras.models.load_model(\n",
        "            MODEL_SAVE_PATH_USEFULNESS\n",
        "        )\n",
        "\n",
        "        test_ds = UsefulnessDataset(X_test, Y_test, y_test, batch_size=batch_size, maxlen=MAXLEN, train=False)\n",
        "        usefulness_model.evaluate(test_ds, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8tPsAjN_JAe",
        "outputId": "e7ef30cd-aab7-4f9d-ce3f-05653fcab546"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing k-fold cross-validation for the Siamese gru ...\n",
            "Testing on Fold #1/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 60/60 [20:35<00:00, 20.59s/epoch, loss=0.1674, binary_accuracy=0.9312, precision=0.8821, recall=0.8190, val_loss=0.2420, val_binary_accuracy=0.9007, val_precision=0.8257, val_recall=0.7318]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4562/4562 [==============================] - 193s 42ms/step - loss: 0.2254 - binary_accuracy: 0.9076 - precision: 0.8377 - recall: 0.7654\n",
            "Testing on Fold #2/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 60/60 [20:02<00:00, 20.04s/epoch, loss=0.1567, binary_accuracy=0.9360, precision=0.8935, recall=0.8257, val_loss=0.2479, val_binary_accuracy=0.8949, val_precision=0.8270, val_recall=0.7089]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4562/4562 [==============================] - 196s 43ms/step - loss: 0.2391 - binary_accuracy: 0.9029 - precision: 0.8449 - recall: 0.7191\n",
            "Testing on Fold #3/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 60/60 [20:04<00:00, 20.08s/epoch, loss=0.1725, binary_accuracy=0.9294, precision=0.8846, recall=0.8048, val_loss=0.2299, val_binary_accuracy=0.9033, val_precision=0.8348, val_recall=0.7342]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4562/4562 [==============================] - 191s 42ms/step - loss: 0.2384 - binary_accuracy: 0.9022 - precision: 0.8328 - recall: 0.7441\n",
            "Testing on Fold #4/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 60/60 [19:58<00:00, 19.98s/epoch, loss=0.1673, binary_accuracy=0.9327, precision=0.8865, recall=0.8172, val_loss=0.2095, val_binary_accuracy=0.9108, val_precision=0.8536, val_recall=0.7645]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4562/4562 [==============================] - 194s 42ms/step - loss: 0.2761 - binary_accuracy: 0.8947 - precision: 0.8025 - recall: 0.7389\n",
            "Testing on Fold #5/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 60/60 [22:10<00:00, 22.17s/epoch, loss=0.1744, binary_accuracy=0.9278, precision=0.8814, recall=0.8017, val_loss=0.2546, val_binary_accuracy=0.8981, val_precision=0.8297, val_recall=0.7173]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4468/4468 [==============================] - 198s 44ms/step - loss: 0.2872 - binary_accuracy: 0.8790 - precision: 0.7710 - recall: 0.7097\n",
            "Performing k-fold cross-validation for the Siamese lstm ...\n",
            "Testing on Fold #1/5 ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 60/60 [25:34<00:00, 25.57s/epoch, loss=0.1546, binary_accuracy=0.9375, precision=0.8981, recall=0.8277, val_loss=0.2415, val_binary_accuracy=0.9031, val_precision=0.8339, val_recall=0.7317]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4562/4562 [==============================] - 208s 45ms/step - loss: 0.2222 - binary_accuracy: 0.9069 - precision: 0.8328 - recall: 0.7687\n",
            "Testing on Fold #2/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 60/60 [22:22<00:00, 22.38s/epoch, loss=0.1483, binary_accuracy=0.9408, precision=0.9037, recall=0.8389, val_loss=0.2336, val_binary_accuracy=0.9089, val_precision=0.8387, val_recall=0.7581]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4562/4562 [==============================] - 210s 46ms/step - loss: 0.2172 - binary_accuracy: 0.9137 - precision: 0.8578 - recall: 0.7590\n",
            "Testing on Fold #3/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 60/60 [21:14<00:00, 21.25s/epoch, loss=0.1617, binary_accuracy=0.9336, precision=0.8890, recall=0.8187, val_loss=0.2507, val_binary_accuracy=0.8968, val_precision=0.8015, val_recall=0.7399]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4562/4562 [==============================] - 206s 45ms/step - loss: 0.2392 - binary_accuracy: 0.9036 - precision: 0.8292 - recall: 0.7556\n",
            "Testing on Fold #4/5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress:  52%|█████▏    | 31/60 [10:45<09:42, 20.08s/epoch, loss=0.2123, binary_accuracy=0.9121, precision=0.8603, recall=0.7475, val_loss=0.2446, val_binary_accuracy=0.9030, val_precision=0.8404, val_recall=0.7348]"
          ]
        }
      ],
      "source": [
        "for seq_module in ['gru', 'lstm', 'transformer']:\n",
        "    print(f'Performing k-fold cross-validation for the Siamese {seq_module} ...')\n",
        "    for test in range(k):\n",
        "        print(f'Testing on Fold #{test+1}/{k} ...')\n",
        "        X_train, X_test, y_train, y_test = split_by_fold(\n",
        "            processed_sequences,\n",
        "            numerical_labels,\n",
        "            folds,\n",
        "            test\n",
        "        )\n",
        "\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_train,\n",
        "            y_train,\n",
        "            test_size=0.2,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        y_train = np.array(y_train, dtype=np.int32)\n",
        "        y_test = np.array(y_test, dtype=np.int32)\n",
        "        y_val = np.array(y_val, dtype=np.int32)\n",
        "\n",
        "        train_batches = 10 * len(X_train) // batch_size\n",
        "        val_batches = 10 * len(X_val) // batch_size\n",
        "        train_ds = SimilarityDataset(X_train, y_train, num_batches=train_batches, batch_size=batch_size, label_angles=label_angles, maxlen=MAXLEN, train=True)\n",
        "        val_ds = SimilarityDataset(X_val, y_val, num_batches=val_batches, batch_size=batch_size, label_angles=label_angles, maxlen=MAXLEN, train=False)\n",
        "\n",
        "        callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "            MODEL_SAVE_PATH_SIMILARITY,\n",
        "            monitor=\"val_binary_accuracy\",\n",
        "            verbose=0,\n",
        "            save_best_only=True,\n",
        "            save_weights_only=False,\n",
        "            mode=\"max\",\n",
        "            save_freq=\"epoch\",\n",
        "            initial_value_threshold=None,\n",
        "        )\n",
        "\n",
        "        pbar_callback = TQDMProgressBar(epochs=60)\n",
        "\n",
        "        # Build and train Siamese model\n",
        "        similarity_model = angle_similarity_model(maxlen=MAXLEN, module=seq_module, lr=1e-3)\n",
        "        history = similarity_model.fit(\n",
        "            train_ds,\n",
        "            validation_data=val_ds,\n",
        "            epochs=60,\n",
        "            callbacks=[callback, pbar_callback],\n",
        "            verbose=0,  # Change this to 1 if you want progressive display while training\n",
        "        )\n",
        "\n",
        "        similarity_model = tf.keras.models.load_model(\n",
        "            MODEL_SAVE_PATH_SIMILARITY,\n",
        "        )\n",
        "\n",
        "        # Make a large dataset in terms of pair in order to have a more reliable test\n",
        "        # since we can't test on all possible pairs (very huge number)\n",
        "        test_batches = 1000 * len(X_test) // batch_size\n",
        "        # Evaluate the Siamese model on the test set\n",
        "        test_ds = SimilarityDataset(X_test, y_test, num_batches=test_batches, batch_size=batch_size, label_angles=label_angles, maxlen=MAXLEN, train=False)\n",
        "        similarity_model.evaluate(test_ds, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ncJ_OCo_1ej"
      },
      "source": [
        "# One-shot Generalization Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3UuYgIW_0kd"
      },
      "outputs": [],
      "source": [
        "tests = [[3, 4, 13, 14, 15, 17], [1, 3, 4, 13, 14, 20], [1, 3, 6, 13, 19, 20], [1, 3, 7, 13, 14, 16], [1, 3, 5, 13, 14, 19], [1, 2, 3, 13, 19, 21], [0, 3, 6, 7, 13, 19], [1, 3, 4, 13, 14, 21], [3, 7, 13, 14, 16, 17], [1, 3, 10, 13, 20, 21]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJar4K7_ADxQ"
      },
      "outputs": [],
      "source": [
        "# Function to split data by specifying test labels\n",
        "def split_by_labels(data_x, data_y, test_labels):\n",
        "    X_train, X_test, y_train, y_test = [], [], [], []\n",
        "    for sample_x, sample_y in zip(data_x, data_y):\n",
        "        if sample_y in test_labels:\n",
        "            X_test.append(sample_x)\n",
        "            y_test.append(sample_y)\n",
        "        else:\n",
        "            X_train.append(sample_x)\n",
        "            y_train.append(sample_y)\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwMU3IQgAq5-"
      },
      "outputs": [],
      "source": [
        "print('Performing one-shot validation for the Angle Usefulness Transformer ...')\n",
        "for test in tests:\n",
        "    print(f'Testing on Exercises: {test} ...')\n",
        "    X_train, X_test, y_train, y_test = split_by_labels(\n",
        "        processed_sequences,\n",
        "        numerical_labels,\n",
        "        test_labels=test,\n",
        "    )\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        test_size=0.2,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    y_train = np.array(y_train, dtype=np.int32)\n",
        "    y_test = np.array(y_test, dtype=np.int32)\n",
        "    y_val = np.array(y_val, dtype=np.int32)\n",
        "\n",
        "    Y_train = np.empty((len(X_train), len(X_train[0][0])), np.float32)\n",
        "    Y_val = np.empty((len(X_val), len(X_train[0][0])), np.float32)\n",
        "    Y_test = np.empty((len(X_test), len(X_train[0][0])), np.float32)\n",
        "\n",
        "    for (Y, y) in [(Y_train, y_train), (Y_val, y_val), (Y_test, y_test)]:\n",
        "        for i in range(Y.shape[0]):\n",
        "            for angle in range(Y.shape[1]):\n",
        "                if angle in label_angles[y[i]]:\n",
        "                    Y[i, angle] = 1\n",
        "                else:\n",
        "                    Y[i, angle] = 0\n",
        "\n",
        "    usefulness_model = angle_usefulness_model(maxlen=MAXLEN, module='transformer', lr=1e-4)\n",
        "\n",
        "    callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        MODEL_SAVE_PATH_USEFULNESS,\n",
        "        monitor=\"val_binary_accuracy\",\n",
        "        verbose=0,\n",
        "        save_best_only=True,\n",
        "        save_weights_only=False,\n",
        "        mode=\"max\",\n",
        "        save_freq=\"epoch\",\n",
        "        initial_value_threshold=None,\n",
        "    )\n",
        "\n",
        "    pbar_callback = TQDMProgressBar(epochs=80)\n",
        "\n",
        "    train_ds = UsefulnessDataset(X_train, Y_train, y_train, batch_size=batch_size, maxlen=MAXLEN, train=True)\n",
        "    val_ds = UsefulnessDataset(X_val, Y_val, y_val, batch_size=min(batch_size, len(X_val)), maxlen=MAXLEN, train=False)\n",
        "\n",
        "    history = usefulness_model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        batch_size=batch_size,\n",
        "        epochs=80,\n",
        "        callbacks=[callback, pbar_callback],\n",
        "        verbose=0,  # Change this to 1 if you want progressive display while training\n",
        "    )\n",
        "\n",
        "    # Load the trained classifier model\n",
        "    usefulness_model = tf.keras.models.load_model(\n",
        "        MODEL_SAVE_PATH_USEFULNESS\n",
        "    )\n",
        "\n",
        "    test_ds = UsefulnessDataset(X_test, Y_test, y_test, batch_size=batch_size, maxlen=MAXLEN, train=False)\n",
        "    usefulness_model.evaluate(test_ds, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFhxjwVJARTw"
      },
      "outputs": [],
      "source": [
        "print('Performing one-shot validation for the Siamese Transformer ...')\n",
        "for test in tests:\n",
        "    print(f'Testing on Exercises: {test} ...')\n",
        "\n",
        "    X_train, X_test, y_train, y_test = split_by_labels(\n",
        "        processed_sequences,\n",
        "        numerical_labels,\n",
        "        test_labels=test,\n",
        "    )\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        test_size=0.2,\n",
        "        random_state=42\n",
        "    )\n",
        "    train_batches = 10 * len(X_train) // batch_size\n",
        "    val_batches = 10 * len(X_val) // batch_size\n",
        "    train_ds = SimilarityDataset(X_train, y_train, num_batches=train_batches, batch_size=batch_size, label_angles=label_angles, maxlen=MAXLEN, train=True)\n",
        "    val_ds = SimilarityDataset(X_val, y_val, num_batches=val_batches, batch_size=batch_size, label_angles=label_angles, maxlen=MAXLEN, train=False)\n",
        "\n",
        "    callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        MODEL_SAVE_PATH_SIMILARITY,\n",
        "        monitor=\"val_binary_accuracy\",\n",
        "        verbose=0,\n",
        "        save_best_only=True,\n",
        "        save_weights_only=False,\n",
        "        mode=\"max\",\n",
        "        save_freq=\"epoch\",\n",
        "        initial_value_threshold=None,\n",
        "    )\n",
        "\n",
        "    pbar_callback = TQDMProgressBar(epochs=60)\n",
        "\n",
        "    # Build and train Siamese model\n",
        "    similarity_model = angle_similarity_model(maxlen=MAXLEN, module='transformer', lr=1e-3)\n",
        "    history = similarity_model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=60,\n",
        "        callbacks=[callback, pbar_callback],\n",
        "        verbose=0,  # Change this to 1 if you want progressive display while training\n",
        "    )\n",
        "\n",
        "    # Load the trained Siamese model\n",
        "    similarity_model = tf.keras.models.load_model(\n",
        "        MODEL_SAVE_PATH_SIMILARITY,\n",
        "    )\n",
        "\n",
        "    # Make a large dataset in terms of pair in order to have a more reliable test\n",
        "    # since we can't test on all possible pairs (very huge number)\n",
        "    test_batches = 1000 * len(X_test) // batch_size\n",
        "    # Evaluate the Siamese model on the test set\n",
        "    test_ds = SimilarityDataset(X_test, y_test, num_batches=test_batches, batch_size=batch_size, label_angles=label_angles, maxlen=MAXLEN, train=False)\n",
        "    similarity_model.evaluate(test_ds, verbose=1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}