{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/asellam/sitrex.git\n",
        "%cd sitrex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC-LL-GZA4ym",
        "outputId": "6e2b0679-1cb3-4677-c969-aa19d78b162c"
      },
      "id": "DC-LL-GZA4ym",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'sitrex' already exists and is not an empty directory.\n",
            "/content/sitrex\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCSGmSbYA-G5",
        "outputId": "502f6a0c-c1f9-4a0c-f527-86468d83e4a3"
      },
      "id": "kCSGmSbYA-G5",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy<2.0,>=1.23 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (1.16.1)\n",
            "Requirement already satisfied: tqdm>=4.65 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (1.6.1)\n",
            "Requirement already satisfied: kagglehub>=0.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (0.3.12)\n",
            "Requirement already satisfied: mediapipe==0.10.21 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (0.10.21)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (0.5.3)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (0.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (3.10.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (4.25.8)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (0.2.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->-r requirements.txt (line 9)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->-r requirements.txt (line 9)) (3.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub>=0.2->-r requirements.txt (line 12)) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub>=0.2->-r requirements.txt (line 12)) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub>=0.2->-r requirements.txt (line 12)) (2.32.3)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.21->-r requirements.txt (line 15)) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe==0.10.21->-r requirements.txt (line 15)) (0.5.3)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe==0.10.21->-r requirements.txt (line 15)) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (2.9.0.post0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub>=0.2->-r requirements.txt (line 12)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub>=0.2->-r requirements.txt (line 12)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub>=0.2->-r requirements.txt (line 12)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub>=0.2->-r requirements.txt (line 12)) (2025.8.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.21->-r requirements.txt (line 15)) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download('hasyimabdillah/workoutfitness-video')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CD6rSFXQBDl_",
        "outputId": "b3581bb5-0792-405d-bbda-bec33e8235fa"
      },
      "id": "CD6rSFXQBDl_",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/hasyimabdillah/workoutfitness-video?dataset_version_number=5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.32G/4.32G [00:39<00:00, 116MB/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "218507cf-175c-483b-8500-a81b4ac3374b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "218507cf-175c-483b-8500-a81b4ac3374b",
        "outputId": "3551c2dd-e9bb-4a18-b7a5-ee9b3661c625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('.')\n",
        "# Import necessary libraries\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sitrex.preprocessing import calculate_angles, get_angle_points\n",
        "from sitrex.model import angle_usefulness_model, angle_similarity_model, TQDMProgressBar\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# EarlyStop save path for the Angle Similarity Transformer\n",
        "MODEL_SAVE_PATH_USEFULNESS = './weights/angle_similarity_model_L300.h5'\n",
        "# EarlyStop save path for the Angle Usefulness Transformer\n",
        "MODEL_SAVE_PATH_SIMILARITY = './weights/angle_usefulness_model_L800.h5'\n",
        "# Batch Size\n",
        "batch_size = 32\n",
        "\n",
        "# Load the trained Siamese model\n",
        "similarity_model = angle_similarity_model(maxlen=300, module='transformer', lr=1e-4)\n",
        "similarity_model.load_weights(MODEL_SAVE_PATH_SIMILARITY)\n",
        "usefulness_model = angle_usefulness_model(maxlen=800, module='transformer', lr=1e-4)\n",
        "usefulness_model.load_weights(MODEL_SAVE_PATH_USEFULNESS)\n",
        "print(\"Models loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "23778025-ea36-4eef-ad26-0c73b1091449",
      "metadata": {
        "id": "23778025-ea36-4eef-ad26-0c73b1091449"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def normalize_landmarks(landmarks):\n",
        "    if not landmarks or len(landmarks) < 33:\n",
        "        return []\n",
        "\n",
        "    # Body center calculation (using hips)\n",
        "    left_hip = landmarks[mp.solutions.pose.PoseLandmark.LEFT_HIP.value]\n",
        "    right_hip = landmarks[mp.solutions.pose.PoseLandmark.RIGHT_HIP.value]\n",
        "    center = {\n",
        "        'x': (left_hip.x + right_hip.x) / 2,\n",
        "        'y': (left_hip.y + right_hip.y) / 2,\n",
        "        'z': (left_hip.z + right_hip.z) / 2\n",
        "    }\n",
        "\n",
        "    # Scale calculation (shoulder width)\n",
        "    left_shoulder = landmarks[mp.solutions.pose.PoseLandmark.LEFT_SHOULDER.value]\n",
        "    right_shoulder = landmarks[mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER.value]\n",
        "    scale = abs(left_shoulder.x - right_shoulder.x) or 1e-5\n",
        "\n",
        "    normalized = []\n",
        "    for lm in landmarks:\n",
        "        normalized.append({\n",
        "            'x': (lm.x - center['x']) / scale,\n",
        "            'y': (lm.y - center['y']) / scale,\n",
        "            'z': lm.z - center['z'],\n",
        "            'visibility': lm.visibility\n",
        "        })\n",
        "    return normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bfd6aa22-1762-4291-8f56-bcd9babd1f0d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfd6aa22-1762-4291-8f56-bcd9babd1f0d",
        "outputId": "f99353fb-b2ac-4bff-a417-dd6b661e996d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading model to /usr/local/lib/python3.12/dist-packages/mediapipe/modules/pose_landmark/pose_landmark_heavy.tflite\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 140/140 [00:16<00:00,  8.39it/s]\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import mediapipe as mp\n",
        "from tqdm import tqdm\n",
        "\n",
        "coach_video = os.path.join(path, 'romanian deadlift/romanian deadlift_10.mp4')\n",
        "athlete_video = os.path.join(path, 'deadlift/deadlift_25.mp4')\n",
        "poser = mp.solutions.pose.Pose(\n",
        "            static_image_mode=False,\n",
        "            model_complexity=2,\n",
        "            min_detection_confidence=0.7,\n",
        "            min_tracking_confidence=0.7\n",
        "        )\n",
        "\n",
        "cap = cv2.VideoCapture(coach_video)\n",
        "T = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "coach_frames = np.empty((T, H, W, 3), np.uint8)\n",
        "coach_angles = np.empty((T, 23), np.uint8)\n",
        "for t in tqdm(range(T)):\n",
        "    success, frame = cap.read()\n",
        "    coach_frames[t, :, :, :] = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    result = poser.process(frame)\n",
        "    landmarks = result.pose_landmarks.landmark\n",
        "    angles = calculate_angles(normalize_landmarks(landmarks))\n",
        "    names = sorted(list(angles.keys()))\n",
        "    angles = [angles[name] for name in names]\n",
        "    coach_angles[t, :] = angles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "be57b2d8-2b22-46c6-aa17-2e7f2915cf72",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be57b2d8-2b22-46c6-aa17-2e7f2915cf72",
        "outputId": "18f7b68b-2d62-464d-f818-e005dfd19eb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step\n",
            "[1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1]\n"
          ]
        }
      ],
      "source": [
        "coach = np.empty((1, usefulness_model.input_shape[1], usefulness_model.input_shape[2]), np.float32)\n",
        "if coach_angles.shape[0] < usefulness_model.input_shape[1]:\n",
        "    coach[0, :coach_angles.shape[0], :] = coach_angles[:, :]\n",
        "    coach[0, coach_angles.shape[0]:, :] = 0\n",
        "else:\n",
        "    coach[0, :, :] = coach_angles[:usefulness_model.input_shape[1], :]\n",
        "usefulness = np.where(usefulness_model.predict(coach)[0] < 0.5, 0, 1)\n",
        "print(usefulness)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "69d41465-eed3-4d4b-983b-c0047ebccea5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69d41465-eed3-4d4b-983b-c0047ebccea5",
        "outputId": "0ae20092-736b-4274-d0bb-e0abcbe644a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [01:54<00:00,  8.22it/s]\n"
          ]
        }
      ],
      "source": [
        "cap = cv2.VideoCapture(athlete_video)\n",
        "T = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "FPS = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "athlete_frames = np.empty((T, H, W, 3), np.uint8)\n",
        "athlete_angles = np.empty((T, 23), np.uint8)\n",
        "athlete_landmarks = []\n",
        "for t in tqdm(range(T)):\n",
        "    success, frame = cap.read()\n",
        "    if success:\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        result = poser.process(frame)\n",
        "        landmarks = result.pose_landmarks.landmark\n",
        "        angles = calculate_angles(normalize_landmarks(landmarks))\n",
        "        names = sorted(list(angles.keys()))\n",
        "        angles = [angles[name] for name in names]\n",
        "        athlete_frames[t, :, :, :] = frame\n",
        "        athlete_angles[t, :] = angles\n",
        "        athlete_landmarks.append(landmarks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "44418621-c69b-4079-96d3-78bedae6ed7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44418621-c69b-4079-96d3-78bedae6ed7c",
        "outputId": "6c4b0455-6e0e-4999-9568-375c1c3a1054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 396ms/step\n"
          ]
        }
      ],
      "source": [
        "coach = np.empty((athlete_angles.shape[0], similarity_model.input_shape[0][1], similarity_model.input_shape[0][2]), np.float32)\n",
        "if coach_angles.shape[0] < similarity_model.input_shape[0][1]:\n",
        "    for t in range(athlete_angles.shape[0]):\n",
        "        coach[t, :coach_angles.shape[0], :] = coach_angles[:, :]\n",
        "        coach[t, coach_angles.shape[0]:, :] = 0\n",
        "else:\n",
        "    for t in range(athlete_angles.shape[0]):\n",
        "        coach[t, :, :] = coach_angles[:similarity_model.input_shape[0][1], :]\n",
        "\n",
        "athlete = np.empty((athlete_angles.shape[0], similarity_model.input_shape[1][1], similarity_model.input_shape[1][2]), np.float32)\n",
        "for t in range(athlete_angles.shape[0]):\n",
        "    if t < similarity_model.input_shape[1][1]:\n",
        "        athlete[t, :t, :] = athlete_angles[:t, :]\n",
        "        athlete[t, t:, :] = 0\n",
        "    else:\n",
        "        athlete[t, :, :] = athlete_angles[t-similarity_model.input_shape[1][1]:t, :]\n",
        "\n",
        "similarity = similarity_model.predict([coach, athlete])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c525383f-f909-4e79-9e86-ffa8294fb340",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "c525383f-f909-4e79-9e86-ffa8294fb340",
        "outputId": "108c68b6-298a-49e8-cf11-db586b622058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/938 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'normalize_angle_points' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-419378381.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mathlete_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mdraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mangle_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_angle_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstandardize_landmarks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlandmarks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangle_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0musefulness\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/sitrex/sitrex/preprocessing.py\u001b[0m in \u001b[0;36mget_angle_points\u001b[0;34m(landmarks)\u001b[0m\n\u001b[1;32m    389\u001b[0m     }\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mangles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mangles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_angle_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mangles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'normalize_angle_points' is not defined"
          ]
        }
      ],
      "source": [
        "from PIL import Image, ImageDraw\n",
        "\n",
        "def standardize_landmarks(landmarks):\n",
        "    if not landmarks or len(landmarks) < 33:\n",
        "        return []\n",
        "    normalized = []\n",
        "    for lm in landmarks:\n",
        "        normalized.append({\n",
        "            'x': lm.x,\n",
        "            'y': lm.y,\n",
        "            'z': lm.z,\n",
        "            'visibility': lm.visibility\n",
        "        })\n",
        "    return normalized\n",
        "\n",
        "def draw_pi_slice(draw, center, point1, point2, fill):\n",
        "    radius = np.linalg.norm(point1 - center)\n",
        "    bbox = [\n",
        "        center[0] - radius, center[1] - radius,\n",
        "        center[0] + radius, center[1] + radius\n",
        "    ]\n",
        "\n",
        "    def angle_between(p, center):\n",
        "        dx = p[0] - center[0]\n",
        "        dy = p[1] - center[1]\n",
        "        angle = np.degrees(np.arctan2(dy, dx)) % 360\n",
        "        return angle\n",
        "\n",
        "    start_angle = angle_between(point1, center)\n",
        "    end_angle = angle_between(point2, center)\n",
        "    if (end_angle - start_angle) % 360 > 180:\n",
        "        end_angle, start_angle = start_angle, end_angle\n",
        "    draw.pieslice(bbox, start=start_angle, end=end_angle, fill=fill)\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "w, h = athlete_frames.shape[2], athlete_frames.shape[1]\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or 'XVID'\n",
        "out = cv2.VideoWriter('output_video.mp4', fourcc, FPS, (w, h))\n",
        "\n",
        "# Write images to video\n",
        "for t in tqdm(range(athlete_frames.shape[0])):\n",
        "    landmarks = athlete_landmarks[t]\n",
        "    frame = Image.fromarray(athlete_frames[t])\n",
        "    draw = ImageDraw.Draw(frame)\n",
        "    angle_points = get_angle_points(standardize_landmarks(landmarks))\n",
        "    for i in range(len(angle_points)):\n",
        "        if usefulness[i] >= 0.5:\n",
        "            a, b, c, d, e = angle_points[names[i]]\n",
        "            r, g = int(255 * (1 - similarity[t, i])), int(255 * similarity[t, i])\n",
        "            draw.line([a[0]*w, a[1]*h, b[0]*w, b[1]*h], fill=(r, g, 0), width=5)\n",
        "            draw.line([a[0]*w, a[1]*h, c[0]*w, c[1]*h], fill=(r, g, 0), width=5)\n",
        "            draw_pi_slice(draw,\n",
        "                          np.array([a[0]*w, a[1]*h]),\n",
        "                          np.array([d[0]*w, d[1]*h]),\n",
        "                          np.array([e[0]*w, e[1]*h]),\n",
        "                          (r, g, 0))\n",
        "    out.write(cv2.cvtColor(np.array(frame), cv2.COLOR_BGR2RGB))  # Add frame\n",
        "\n",
        "# Release everything\n",
        "out.release()\n",
        "print(\"Video saved as output_video.mp4\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}