{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/asellam/sitrex.git\n",
        "%cd sitrex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC-LL-GZA4ym",
        "outputId": "54442eab-91df-4328-c91f-1395763645bf"
      },
      "id": "DC-LL-GZA4ym",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'sitrex' already exists and is not an empty directory.\n",
            "/content/sitrex\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kCSGmSbYA-G5",
        "outputId": "bfcd6ebe-45ea-4fe4-afd6-80ebd0bad85d"
      },
      "id": "kCSGmSbYA-G5",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<2.0,>=1.23 (from -r requirements.txt (line 2))\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (1.16.1)\n",
            "Requirement already satisfied: tqdm>=4.65 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (1.6.1)\n",
            "Requirement already satisfied: kagglehub>=0.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (0.3.12)\n",
            "Collecting mediapipe==0.10.21 (from -r requirements.txt (line 15))\n",
            "  Downloading mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (0.5.3)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (0.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (3.10.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (4.12.0.88)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe==0.10.21->-r requirements.txt (line 15))\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe==0.10.21->-r requirements.txt (line 15))\n",
            "  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.21->-r requirements.txt (line 15)) (0.2.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->-r requirements.txt (line 9)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->-r requirements.txt (line 9)) (3.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub>=0.2->-r requirements.txt (line 12)) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub>=0.2->-r requirements.txt (line 12)) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub>=0.2->-r requirements.txt (line 12)) (2.32.3)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.21->-r requirements.txt (line 15)) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe==0.10.21->-r requirements.txt (line 15)) (0.5.3)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe==0.10.21->-r requirements.txt (line 15)) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (2.9.0.post0)\n",
            "INFO: pip is looking at multiple versions of opencv-contrib-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-contrib-python (from mediapipe==0.10.21->-r requirements.txt (line 15))\n",
            "  Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub>=0.2->-r requirements.txt (line 12)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub>=0.2->-r requirements.txt (line 12)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub>=0.2->-r requirements.txt (line 12)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub>=0.2->-r requirements.txt (line 12)) (2025.8.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.21->-r requirements.txt (line 15)) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.21->-r requirements.txt (line 15)) (1.17.0)\n",
            "Downloading mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\n",
            "Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, numpy, sounddevice, opencv-contrib-python, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.12.0.88\n",
            "    Uninstalling opencv-contrib-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-contrib-python-4.12.0.88\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.21 numpy-1.26.4 opencv-contrib-python-4.11.0.86 protobuf-4.25.8 sounddevice-0.5.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              },
              "id": "a2da37463041474b98aedeca9cbc20f5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download('hasyimabdillah/workoutfitness-video')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CD6rSFXQBDl_",
        "outputId": "85a28446-b1e2-47df-a67b-2c72ffd6db79"
      },
      "id": "CD6rSFXQBDl_",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/hasyimabdillah/workoutfitness-video?dataset_version_number=5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.32G/4.32G [00:54<00:00, 84.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "218507cf-175c-483b-8500-a81b4ac3374b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "218507cf-175c-483b-8500-a81b4ac3374b",
        "outputId": "f62d94bc-f36d-4457-ea0d-bfb3c58759de"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1919043369.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Load the trained Siamese model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0msimilarity_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mangle_similarity_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'transformer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0msimilarity_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_SAVE_PATH_SIMILARITY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0musefulness_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mangle_usefulness_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'transformer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/sitrex/sitrex/model.py\u001b[0m in \u001b[0;36mangle_similarity_model\u001b[0;34m(maxlen, module, embed_dim, num_heads, ff_dim, lr)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0membedding_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0membedding_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_l\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0membedding_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_r\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/common/keras_tensor.py\u001b[0m in \u001b[0;36m__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__tf_tensor__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0;34m\"A KerasTensor cannot be used as input to a TensorFlow function. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;34m\"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('.')\n",
        "# Import necessary libraries\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sitrex.preprocessing import calculate_angles\n",
        "from sitrex.model import angle_usefulness_model, angle_similarity_model, TQDMProgressBar\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "# Define constants\n",
        "DATASET_PATH = os.path.join(path, 'dataset')\n",
        "# EarlyStop save path for the Angle Similarity Transformer\n",
        "MODEL_SAVE_PATH_USEFULNESS = './angle_similarity_model_L800.h5'\n",
        "# EarlyStop save path for the Angle Usefulness Transformer\n",
        "MODEL_SAVE_PATH_SIMILARITY = './angle_usefulness_model_L300.h5'\n",
        "# Batch Size\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "# Load the trained Siamese model\n",
        "similarity_model = angle_similarity_model(maxlen=300, module='transformer', lr=1e-4)\n",
        "similarity_model.load_weights(MODEL_SAVE_PATH_SIMILARITY)\n",
        "usefulness_model = angle_usefulness_model(maxlen=800, module='transformer', lr=1e-4)\n",
        "usefulness_model.load_weights(MODEL_SAVE_PATH_USEFULNESS)\n",
        "print(\"Models loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "23778025-ea36-4eef-ad26-0c73b1091449",
      "metadata": {
        "id": "23778025-ea36-4eef-ad26-0c73b1091449"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def normalize(v):\n",
        "    norm = np.linalg.norm(v)\n",
        "    return v / norm if norm != 0 else v\n",
        "\n",
        "def point(landmark):\n",
        "    return np.array([landmark['x'], landmark['y'], landmark['z']])\n",
        "\n",
        "# Function to calculate the 3D angle between three points\n",
        "def angle_between(a, b):\n",
        "    cosine_angle = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-6)\n",
        "    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
        "    return np.degrees(angle)\n",
        "\n",
        "def vector(start, end):\n",
        "    return np.array([end['x'] - start['x'], end['y'] - start['y'], end['z'] - start['z']])\n",
        "\n",
        "def calculate_angle(a, b, c):\n",
        "    return angle_between(vector(b, a), vector(b, c))\n",
        "\n",
        "def midpoint(a, b):\n",
        "    return (a + b) / 2\n",
        "\n",
        "def vector_plane_project(vector, plane_normal):\n",
        "    vector_proj = vector - np.dot(vector, plane_normal) * plane_normal\n",
        "    vector_proj = normalize(vector_proj)\n",
        "    return vector_proj\n",
        "\n",
        "\n",
        "# Function to compute 23 specific angles from 33 keypoints\n",
        "def calculate_angles(landmarks):\n",
        "    \"\"\"Compute 20 joint-angle features from Mediapipe landmarks.\"\"\"\n",
        "    if not landmarks or len(landmarks) < 33:\n",
        "        return [0.0] * NUM_FEATURES\n",
        "    # Define landmark indices\n",
        "    LEFT_SHOULDER, RIGHT_SHOULDER = 11, 12\n",
        "    LEFT_ELBOW, RIGHT_ELBOW = 13, 14\n",
        "    LEFT_WRIST, RIGHT_WRIST = 15, 16\n",
        "    LEFT_WRIST, RIGHT_WRIST = 15, 16\n",
        "    LEFT_PINKY, RIGHT_PINKY = 17, 18\n",
        "    LEFT_INDEX,RIGHT_INDEX = 19, 20\n",
        "    LEFT_HIP, RIGHT_HIP = 23, 24\n",
        "    LEFT_KNEE, RIGHT_KNEE = 25, 26\n",
        "    LEFT_ANKLE, RIGHT_ANKLE = 27, 28\n",
        "\n",
        "    # Estimating Primary Vectors\n",
        "    L_shoulder = point(landmarks[LEFT_SHOULDER])  # LEFT_SHOULDER\n",
        "    R_shoulder = point(landmarks[RIGHT_SHOULDER])  # RIGHT_SHOULDER\n",
        "    L_hip = point(landmarks[LEFT_HIP])       # LEFT_HIP\n",
        "    R_hip = point(landmarks[RIGHT_HIP])       # RIGHT_HIP\n",
        "    L_ankle = point(landmarks[LEFT_ANKLE])       # LEFT_ANKLE\n",
        "    R_ankle = point(landmarks[RIGHT_ANKLE])       # RIGHT_ANKLE\n",
        "\n",
        "    # Midpoints\n",
        "    mid_shoulder = midpoint(L_shoulder, R_shoulder)\n",
        "    mid_hip = midpoint(L_hip, R_hip)\n",
        "\n",
        "    # Local torso axes\n",
        "    horizontal = normalize(R_shoulder - L_shoulder)           # Local X (shoulder width)\n",
        "    upward = normalize(mid_shoulder - mid_hip)          # Local Y (torso up)\n",
        "    forward = normalize(np.cross(horizontal, upward))          # Local Z (front-back normal to torso plane)\n",
        "    # Re-orthogonalize Y just in case (to maintain right-handed frame)\n",
        "    upward = normalize(np.cross(forward, horizontal))\n",
        "\n",
        "    # Torso flexion\n",
        "    mid_ankle = midpoint(L_ankle, R_ankle)\n",
        "    torso = mid_shoulder - mid_hip\n",
        "    gravity = mid_ankle - mid_hip\n",
        "    torso_flexion = angle_between(torso, gravity)\n",
        "\n",
        "    # Elbow\n",
        "    left_elbow = calculate_angle(landmarks[LEFT_SHOULDER], landmarks[LEFT_ELBOW], landmarks[LEFT_WRIST])\n",
        "    right_elbow = calculate_angle(landmarks[RIGHT_SHOULDER], landmarks[RIGHT_ELBOW], landmarks[RIGHT_WRIST])\n",
        "\n",
        "    # Shoulder\n",
        "    left_shoulder = calculate_angle(landmarks[LEFT_HIP], landmarks[LEFT_SHOULDER], landmarks[LEFT_ELBOW])\n",
        "    right_shoulder = calculate_angle(landmarks[RIGHT_HIP], landmarks[RIGHT_SHOULDER], landmarks[RIGHT_ELBOW])\n",
        "\n",
        "    # Spinal alignment\n",
        "    left_hand = midpoint(point(landmarks[LEFT_PINKY]), point(landmarks[LEFT_INDEX]))\n",
        "    left_wrist = angle_between(left_hand - point(landmarks[LEFT_WRIST]),\n",
        "                               point(landmarks[LEFT_ELBOW]) - point(landmarks[LEFT_WRIST]))\n",
        "    right_hand = midpoint(point(landmarks[RIGHT_PINKY]), point(landmarks[RIGHT_INDEX]))\n",
        "    right_wrist = angle_between(right_hand - point(landmarks[RIGHT_WRIST]),\n",
        "                                point(landmarks[RIGHT_ELBOW]) - point(landmarks[RIGHT_WRIST]))\n",
        "\n",
        "    # Scapular upward rotation\n",
        "    left_scapular_upward_rotation = angle_between(vector(landmarks[LEFT_HIP], landmarks[LEFT_SHOULDER]),\n",
        "                                                  vector(landmarks[LEFT_HIP], landmarks[RIGHT_HIP]))\n",
        "\n",
        "    right_scapular_upward_rotation = angle_between(vector(landmarks[RIGHT_HIP], landmarks[RIGHT_SHOULDER]),\n",
        "                                                   vector(landmarks[RIGHT_HIP], landmarks[LEFT_HIP]))\n",
        "\n",
        "    # Shoulder abduction/extension\n",
        "    v_arm_left = vector(landmarks[LEFT_SHOULDER],  landmarks[LEFT_ELBOW])\n",
        "    f_proj_v_arm_left = vector_plane_project(v_arm_left, forward)\n",
        "    f_left_shoulder_abduction = angle_between(f_proj_v_arm_left, upward)\n",
        "    h_proj_v_arm_left = vector_plane_project(v_arm_left, upward)\n",
        "    h_left_shoulder_adduction = angle_between(h_proj_v_arm_left, forward)\n",
        "    s_proj_v_arm_left = vector_plane_project(v_arm_left, horizontal)\n",
        "    left_shoulder_extension = angle_between(s_proj_v_arm_left, upward)\n",
        "\n",
        "    v_arm_right = vector(landmarks[RIGHT_SHOULDER],  landmarks[RIGHT_ELBOW])\n",
        "    f_proj_v_arm_right = vector_plane_project(v_arm_right, forward)\n",
        "    f_right_shoulder_abduction = angle_between(f_proj_v_arm_right, upward)\n",
        "    h_proj_v_arm_right = vector_plane_project(v_arm_right, upward)\n",
        "    h_right_shoulder_adduction = angle_between(h_proj_v_arm_right, forward)\n",
        "    s_proj_v_arm_right = vector_plane_project(v_arm_right, horizontal)\n",
        "    right_shoulder_extension = angle_between(s_proj_v_arm_right, upward)\n",
        "\n",
        "    # Knee\n",
        "    left_knee = calculate_angle(landmarks[LEFT_HIP], landmarks[LEFT_KNEE], landmarks[LEFT_ANKLE])\n",
        "    right_knee = calculate_angle(landmarks[RIGHT_HIP], landmarks[RIGHT_KNEE], landmarks[RIGHT_ANKLE])\n",
        "\n",
        "    # Hip\n",
        "    left_hip = calculate_angle(landmarks[LEFT_SHOULDER], landmarks[LEFT_HIP], landmarks[LEFT_KNEE])\n",
        "    right_hip = calculate_angle(landmarks[RIGHT_SHOULDER], landmarks[RIGHT_HIP], landmarks[RIGHT_KNEE])\n",
        "\n",
        "    # Ankle dorsiflexion\n",
        "    v_shin_left = vector(landmarks[LEFT_KNEE],  landmarks[LEFT_ANKLE])\n",
        "    s_proj_v_shin_left = vector_plane_project(v_shin_left, horizontal)\n",
        "    left_ankle_dorsiflexion = angle_between(s_proj_v_shin_left, upward)\n",
        "\n",
        "    v_shin_right = vector(landmarks[RIGHT_KNEE],  landmarks[RIGHT_ANKLE])\n",
        "    s_proj_v_shin_right = vector_plane_project(v_shin_right, horizontal)\n",
        "    right_ankle_dorsiflexion = angle_between(s_proj_v_shin_right, upward)\n",
        "\n",
        "    # Left knee valgus indicator\n",
        "    f_proj_left_hip = vector_plane_project(point(landmarks[LEFT_HIP]), forward)\n",
        "    f_proj_left_knee = vector_plane_project(point(landmarks[LEFT_KNEE]), forward)\n",
        "    f_proj_left_ankle = vector_plane_project(point(landmarks[LEFT_ANKLE]), forward)\n",
        "    left_knee_valgus_indicator = angle_between(f_proj_left_hip - f_proj_left_knee, f_proj_left_ankle - f_proj_left_knee)\n",
        "    # Right knee valgus indicator\n",
        "    f_proj_right_hip = vector_plane_project(point(landmarks[RIGHT_HIP]), forward)\n",
        "    f_proj_right_knee = vector_plane_project(point(landmarks[RIGHT_KNEE]), forward)\n",
        "    f_proj_right_ankle = vector_plane_project(point(landmarks[RIGHT_ANKLE]), forward)\n",
        "    right_knee_valgus_indicator = angle_between(f_proj_right_hip - f_proj_right_knee, f_proj_right_ankle - f_proj_right_knee)\n",
        "\n",
        "    angles = {\n",
        "        'torso flexion': torso_flexion,\n",
        "        'left elbow': left_elbow,\n",
        "        'right elbow': right_elbow,\n",
        "        'left shoulder': left_shoulder,\n",
        "        'right shoulder': right_shoulder,\n",
        "        'left wrist': left_wrist,\n",
        "        'right wrist': right_wrist,\n",
        "        'left frontal shoulder abduction': f_left_shoulder_abduction,\n",
        "        'right frontal shoulder abduction': f_right_shoulder_abduction,\n",
        "        'left scapular upward rotation': left_scapular_upward_rotation,\n",
        "        'right scapular upward rotation': right_scapular_upward_rotation,\n",
        "        'left knee': left_knee,\n",
        "        'right knee': right_knee,\n",
        "        'left hip': left_hip,\n",
        "        'right hip': right_hip,\n",
        "        'left ankle dorsiflexion': left_ankle_dorsiflexion,\n",
        "        'right ankle dorsiflexion': right_ankle_dorsiflexion,\n",
        "        'left knee valgus indicator': left_knee_valgus_indicator,\n",
        "        'right knee valgus indicator': right_knee_valgus_indicator,\n",
        "        'left horizontal shoulder adduction': h_left_shoulder_adduction,\n",
        "        'right horizontal shoulder adduction': h_right_shoulder_adduction,\n",
        "        'left shoulder extension': left_shoulder_extension,\n",
        "        'right shoulder extension': right_shoulder_extension,\n",
        "    }\n",
        "\n",
        "    return angles\n",
        "\n",
        "def normalize_landmarks(landmarks):\n",
        "    if not landmarks or len(landmarks) < 33:\n",
        "        return []\n",
        "\n",
        "    # Body center calculation (using hips)\n",
        "    left_hip = landmarks[mp.solutions.pose.PoseLandmark.LEFT_HIP.value]\n",
        "    right_hip = landmarks[mp.solutions.pose.PoseLandmark.RIGHT_HIP.value]\n",
        "    center = {\n",
        "        'x': (left_hip.x + right_hip.x) / 2,\n",
        "        'y': (left_hip.y + right_hip.y) / 2,\n",
        "        'z': (left_hip.z + right_hip.z) / 2\n",
        "    }\n",
        "\n",
        "    # Scale calculation (shoulder width)\n",
        "    left_shoulder = landmarks[mp.solutions.pose.PoseLandmark.LEFT_SHOULDER.value]\n",
        "    right_shoulder = landmarks[mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER.value]\n",
        "    scale = abs(left_shoulder.x - right_shoulder.x) or 1e-5\n",
        "\n",
        "    normalized = []\n",
        "    for lm in landmarks:\n",
        "        normalized.append({\n",
        "            'x': (lm.x - center['x']) / scale,\n",
        "            'y': (lm.y - center['y']) / scale,\n",
        "            'z': lm.z - center['z'],\n",
        "            'visibility': lm.visibility\n",
        "        })\n",
        "    return normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfd6aa22-1762-4291-8f56-bcd9babd1f0d",
      "metadata": {
        "id": "bfd6aa22-1762-4291-8f56-bcd9babd1f0d",
        "outputId": "4b42c2ab-1c4b-4190-ee3d-c882c964e761"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████| 140/140 [00:32<00:00,  4.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total frames: 140\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import mediapipe as mp\n",
        "from tqdm import tqdm\n",
        "\n",
        "coach_video = 'videos/romanian deadlift/romanian deadlift_10.mp4'\n",
        "athlete_video = 'videos/deadlift/deadlift_25.mp4'\n",
        "poser = mp.solutions.pose.Pose(\n",
        "            static_image_mode=False,\n",
        "            model_complexity=2,\n",
        "            min_detection_confidence=0.7,\n",
        "            min_tracking_confidence=0.7\n",
        "        )\n",
        "\n",
        "cap = cv2.VideoCapture(coach_video)\n",
        "T = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "coach_angles = np.empty((T, 23), np.uint8)\n",
        "for t in tqdm(range(T)):\n",
        "    success, frame = cap.read()\n",
        "    coach_frames[t, :, :, :] = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    result = poser.process(frame)\n",
        "    landmarks = result.pose_landmarks.landmark\n",
        "    angles = calculate_angles(normalize_landmarks(landmarks))\n",
        "    names = sorted(list(angles.keys()))\n",
        "    angles = [angles[name] for name in names]\n",
        "    coach_angles[t, :] = angles\n",
        "print(\"Total frames:\", frame_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be57b2d8-2b22-46c6-aa17-2e7f2915cf72",
      "metadata": {
        "id": "be57b2d8-2b22-46c6-aa17-2e7f2915cf72",
        "outputId": "d23d51d2-f68a-4a54-d232-f7e5a0195960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
            "[0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1]\n"
          ]
        }
      ],
      "source": [
        "coach = np.empty((1, classifier_model.input_shape[1], classifier_model.input_shape[2]), np.float32)\n",
        "if coach_angles.shape[0] < classifier_model.input_shape[1]:\n",
        "    coach[0, :coach_angles.shape[0], :] = coach_angles[:, :]\n",
        "    coach[0, coach_angles.shape[0]:, :] = 0\n",
        "else:\n",
        "    coach[0, :, :] = coach_angles[:classifier_model.input_shape[1], :]\n",
        "usefulness = np.where(classifier_model.predict(coach)[0] < 0.5, 0, 1)\n",
        "print(usefulness)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69d41465-eed3-4d4b-983b-c0047ebccea5",
      "metadata": {
        "id": "69d41465-eed3-4d4b-983b-c0047ebccea5",
        "outputId": "4db85512-eb10-4bb2-b6ea-22598921ff74"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████| 938/938 [01:44<00:00,  8.95it/s]\n"
          ]
        }
      ],
      "source": [
        "cap = cv2.VideoCapture(athlete_video)\n",
        "T = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "FPS = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "athlete_frames = np.empty((T, H, W, 3), np.uint8)\n",
        "athlete_angles = np.empty((T, 23), np.uint8)\n",
        "athlete_landmarks = []\n",
        "for t in tqdm(range(T)):\n",
        "    success, frame = cap.read()\n",
        "    if success:\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        result = poser.process(frame)\n",
        "        landmarks = result.pose_landmarks.landmark\n",
        "        angles = calculate_angles(normalize_landmarks(landmarks))\n",
        "        names = sorted(list(angles.keys()))\n",
        "        angles = [angles[name] for name in names]\n",
        "        athlete_frames[t, :, :, :] = frame\n",
        "        athlete_angles[t, :] = angles\n",
        "        athlete_landmarks.append(landmarks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44418621-c69b-4079-96d3-78bedae6ed7c",
      "metadata": {
        "id": "44418621-c69b-4079-96d3-78bedae6ed7c",
        "outputId": "36ed57d5-4975-4a14-eb25-d8da5038fc6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step\n"
          ]
        }
      ],
      "source": [
        "coach = np.empty((athlete_angles.shape[0], siamese_model.input_shape[0][1], siamese_model.input_shape[0][2]), np.float32)\n",
        "if coach_angles.shape[0] < classifier_model.input_shape[1]:\n",
        "    for t in range(athlete_angles.shape[0]):\n",
        "        coach[t, :coach_angles.shape[0], :] = coach_angles[:, :]\n",
        "        coach[t, coach_angles.shape[0]:, :] = 0\n",
        "else:\n",
        "    for t in range(athlete_angles.shape[0]):\n",
        "        coach[t, :, :] = coach_angles[:siamese_model.input_shape[0][1], :]\n",
        "\n",
        "athlete = np.empty((athlete_angles.shape[0], siamese_model.input_shape[1][1], siamese_model.input_shape[1][2]), np.float32)\n",
        "for t in range(athlete_angles.shape[0]):\n",
        "    if t < siamese_model.input_shape[1][1]:\n",
        "        athlete[t, :t, :] = athlete_angles[:t, :]\n",
        "        athlete[t, t:, :] = 0\n",
        "    else:\n",
        "        athlete[t, :, :] = athlete_angles[t-siamese_model.input_shape[1][1]:t, :]\n",
        "\n",
        "similarity = siamese_model.predict([coach, athlete])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c525383f-f909-4e79-9e86-ffa8294fb340",
      "metadata": {
        "id": "c525383f-f909-4e79-9e86-ffa8294fb340",
        "outputId": "d4d92b96-6d8a-4f15-f476-4896d5a4f80e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████| 938/938 [00:20<00:00, 46.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video saved as output_video.mp4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image, ImageDraw\n",
        "# Function to compute 23 specific angles from 33 keypoints\n",
        "def get_angle_points(landmarks):\n",
        "    \"\"\"Compute 20 joint-angle features from Mediapipe landmarks.\"\"\"\n",
        "    if not landmarks or len(landmarks) < 33:\n",
        "        return [0.0] * NUM_FEATURES\n",
        "    # Define landmark indices\n",
        "    LEFT_SHOULDER, RIGHT_SHOULDER = 11, 12\n",
        "    LEFT_ELBOW, RIGHT_ELBOW = 13, 14\n",
        "    LEFT_WRIST, RIGHT_WRIST = 15, 16\n",
        "    LEFT_WRIST, RIGHT_WRIST = 15, 16\n",
        "    LEFT_PINKY, RIGHT_PINKY = 17, 18\n",
        "    LEFT_INDEX,RIGHT_INDEX = 19, 20\n",
        "    LEFT_HIP, RIGHT_HIP = 23, 24\n",
        "    LEFT_KNEE, RIGHT_KNEE = 25, 26\n",
        "    LEFT_ANKLE, RIGHT_ANKLE = 27, 28\n",
        "\n",
        "    # Estimating Primary Vectors\n",
        "    L_shoulder = point(landmarks[LEFT_SHOULDER])  # LEFT_SHOULDER\n",
        "    R_shoulder = point(landmarks[RIGHT_SHOULDER])  # RIGHT_SHOULDER\n",
        "    L_hip = point(landmarks[LEFT_HIP])       # LEFT_HIP\n",
        "    R_hip = point(landmarks[RIGHT_HIP])       # RIGHT_HIP\n",
        "    L_ankle = point(landmarks[LEFT_ANKLE])       # LEFT_ANKLE\n",
        "    R_ankle = point(landmarks[RIGHT_ANKLE])       # RIGHT_ANKLE\n",
        "\n",
        "    # Midpoints\n",
        "    mid_shoulder = midpoint(L_shoulder, R_shoulder)\n",
        "    mid_hip = midpoint(L_hip, R_hip)\n",
        "\n",
        "    # Local torso axes\n",
        "    horizontal = normalize(R_shoulder - L_shoulder)           # Local X (shoulder width)\n",
        "    upward = normalize(mid_shoulder - mid_hip)          # Local Y (torso up)\n",
        "    forward = normalize(np.cross(horizontal, upward))          # Local Z (front-back normal to torso plane)\n",
        "    # Re-orthogonalize Y just in case (to maintain right-handed frame)\n",
        "    upward = normalize(np.cross(forward, horizontal))\n",
        "\n",
        "    # Torso flexion\n",
        "    mid_ankle = midpoint(L_ankle, R_ankle)\n",
        "    torso = mid_shoulder - mid_hip\n",
        "    gravity = mid_ankle - mid_hip\n",
        "    torso_flexion = (mid_shoulder, mid_hip, mid_ankle)\n",
        "\n",
        "    # Elbow\n",
        "    left_elbow = (point(landmarks[LEFT_WRIST]), point(landmarks[LEFT_ELBOW]), point(landmarks[LEFT_SHOULDER]))\n",
        "    right_elbow = (point(landmarks[RIGHT_WRIST]), point(landmarks[RIGHT_ELBOW]), point(landmarks[RIGHT_SHOULDER]))\n",
        "\n",
        "    # Shoulder\n",
        "    left_shoulder = (point(landmarks[LEFT_HIP]), point(landmarks[LEFT_SHOULDER]), point(landmarks[LEFT_ELBOW]))\n",
        "    right_shoulder = (point(landmarks[RIGHT_HIP]), point(landmarks[RIGHT_SHOULDER]), point(landmarks[RIGHT_ELBOW]))\n",
        "\n",
        "    # Wrist\n",
        "    left_hand = midpoint(point(landmarks[LEFT_PINKY]), point(landmarks[LEFT_INDEX]))\n",
        "    left_wrist = (left_hand, point(landmarks[LEFT_WRIST]), point(landmarks[LEFT_ELBOW]))\n",
        "    right_hand = midpoint(point(landmarks[RIGHT_PINKY]), point(landmarks[RIGHT_INDEX]))\n",
        "    right_wrist = (right_hand, point(landmarks[RIGHT_WRIST]), point(landmarks[RIGHT_ELBOW]))\n",
        "\n",
        "    # Scapular upward rotation\n",
        "    left_scapular_upward_rotation = (point(landmarks[LEFT_SHOULDER]), point(landmarks[LEFT_HIP]),  point(landmarks[RIGHT_HIP]))\n",
        "\n",
        "    right_scapular_upward_rotation = (point(landmarks[RIGHT_SHOULDER]), point(landmarks[RIGHT_HIP]),  point(landmarks[LEFT_HIP]))\n",
        "\n",
        "    # Shoulder abduction/extension\n",
        "    shoulder = point(landmarks[LEFT_SHOULDER])\n",
        "    v_arm_left = vector(landmarks[LEFT_SHOULDER],  landmarks[LEFT_ELBOW])\n",
        "    f_proj_v_arm_left = vector_plane_project(v_arm_left, forward)\n",
        "    f_left_shoulder_abduction = (shoulder + f_proj_v_arm_left, shoulder, shoulder + upward)\n",
        "    h_proj_v_arm_left = vector_plane_project(v_arm_left, upward)\n",
        "    h_left_shoulder_adduction = (shoulder + h_proj_v_arm_left, shoulder, shoulder + forward)\n",
        "    s_proj_v_arm_left = vector_plane_project(v_arm_left, horizontal)\n",
        "    left_shoulder_extension = (shoulder + s_proj_v_arm_left, shoulder, shoulder + upward)\n",
        "\n",
        "    shoulder = point(landmarks[RIGHT_SHOULDER])\n",
        "    v_arm_right = vector(landmarks[RIGHT_SHOULDER],  landmarks[RIGHT_ELBOW])\n",
        "    f_proj_v_arm_right = vector_plane_project(v_arm_right, forward)\n",
        "    f_right_shoulder_abduction = (shoulder + f_proj_v_arm_right, shoulder, shoulder + upward)\n",
        "    h_proj_v_arm_right = vector_plane_project(v_arm_right, upward)\n",
        "    h_right_shoulder_adduction = (shoulder + h_proj_v_arm_right, shoulder, shoulder + forward)\n",
        "    s_proj_v_arm_right = vector_plane_project(v_arm_right, horizontal)\n",
        "    right_shoulder_extension = (shoulder + s_proj_v_arm_right, shoulder, shoulder + upward)\n",
        "\n",
        "    # Knee\n",
        "    left_knee = (point(landmarks[LEFT_HIP]), point(landmarks[LEFT_KNEE]), point(landmarks[LEFT_ANKLE]))\n",
        "    right_knee = (point(landmarks[RIGHT_HIP]), point(landmarks[RIGHT_KNEE]), point(landmarks[RIGHT_ANKLE]))\n",
        "\n",
        "    # Hip\n",
        "    left_hip = (point(landmarks[LEFT_SHOULDER]), point(landmarks[LEFT_HIP]), point(landmarks[LEFT_KNEE]))\n",
        "    right_hip = (point(landmarks[RIGHT_SHOULDER]), point(landmarks[RIGHT_HIP]), point(landmarks[RIGHT_KNEE]))\n",
        "\n",
        "    # Ankle dorsiflexion\n",
        "    ankle = point(landmarks[LEFT_ANKLE])\n",
        "    v_shin_left = vector(landmarks[LEFT_KNEE],  landmarks[LEFT_ANKLE])\n",
        "    s_proj_v_shin_left = vector_plane_project(v_shin_left, horizontal)\n",
        "    left_ankle_dorsiflexion = (ankle + s_proj_v_shin_left, ankle, ankle + upward)\n",
        "\n",
        "    ankle = point(landmarks[RIGHT_ANKLE])\n",
        "    v_shin_right = vector(landmarks[RIGHT_KNEE],  landmarks[RIGHT_ANKLE])\n",
        "    s_proj_v_shin_right = vector_plane_project(v_shin_right, horizontal)\n",
        "    right_ankle_dorsiflexion = (ankle + s_proj_v_shin_right, ankle, ankle + upward)\n",
        "\n",
        "    # Left knee valgus indicator\n",
        "    knee = point(landmarks[LEFT_KNEE])\n",
        "    f_proj_left_hip = vector_plane_project(point(landmarks[LEFT_HIP]), forward)\n",
        "    f_proj_left_knee = vector_plane_project(point(landmarks[LEFT_KNEE]), forward)\n",
        "    f_proj_left_ankle = vector_plane_project(point(landmarks[LEFT_ANKLE]), forward)\n",
        "    left_knee_valgus_indicator = (knee + f_proj_left_hip - f_proj_left_knee, knee, knee + f_proj_left_ankle - f_proj_left_knee)\n",
        "    # Right knee valgus indicator\n",
        "    knee = point(landmarks[RIGHT_KNEE])\n",
        "    f_proj_right_hip = vector_plane_project(point(landmarks[RIGHT_HIP]), forward)\n",
        "    f_proj_right_knee = vector_plane_project(point(landmarks[RIGHT_KNEE]), forward)\n",
        "    f_proj_right_ankle = vector_plane_project(point(landmarks[RIGHT_ANKLE]), forward)\n",
        "    right_knee_valgus_indicator = (knee + f_proj_right_hip - f_proj_right_knee, knee, knee + f_proj_right_ankle - f_proj_right_knee)\n",
        "\n",
        "    angles = {\n",
        "        'torso flexion': torso_flexion,\n",
        "        'left elbow': left_elbow,\n",
        "        'right elbow': right_elbow,\n",
        "        'left shoulder': left_shoulder,\n",
        "        'right shoulder': right_shoulder,\n",
        "        'left wrist': left_wrist,\n",
        "        'right wrist': right_wrist,\n",
        "        'left frontal shoulder abduction': f_left_shoulder_abduction,\n",
        "        'right frontal shoulder abduction': f_right_shoulder_abduction,\n",
        "        'left scapular upward rotation': left_scapular_upward_rotation,\n",
        "        'right scapular upward rotation': right_scapular_upward_rotation,\n",
        "        'left knee': left_knee,\n",
        "        'right knee': right_knee,\n",
        "        'left hip': left_hip,\n",
        "        'right hip': right_hip,\n",
        "        'left ankle dorsiflexion': left_ankle_dorsiflexion,\n",
        "        'right ankle dorsiflexion': right_ankle_dorsiflexion,\n",
        "        'left knee valgus indicator': left_knee_valgus_indicator,\n",
        "        'right knee valgus indicator': right_knee_valgus_indicator,\n",
        "        'left horizontal shoulder adduction': h_left_shoulder_adduction,\n",
        "        'right horizontal shoulder adduction': h_right_shoulder_adduction,\n",
        "        'left shoulder extension': left_shoulder_extension,\n",
        "        'right shoulder extension': right_shoulder_extension,\n",
        "    }\n",
        "    for key in angles:\n",
        "        angles[key] = normalize_angle_points(angles[key])\n",
        "    return angles\n",
        "\n",
        "def standardize_landmarks(landmarks):\n",
        "    if not landmarks or len(landmarks) < 33:\n",
        "        return []\n",
        "    normalized = []\n",
        "    for lm in landmarks:\n",
        "        normalized.append({\n",
        "            'x': lm.x,\n",
        "            'y': lm.y,\n",
        "            'z': lm.z,\n",
        "            'visibility': lm.visibility\n",
        "        })\n",
        "    return normalized\n",
        "\n",
        "def normalize_angle_points(points):\n",
        "    a, b, c = points\n",
        "    la = np.linalg.norm(a - b)\n",
        "    lc = np.linalg.norm(c - b)\n",
        "    lm = max(la, lc)\n",
        "    d = b + (a - b) * lm / la * 0.1\n",
        "    e = b + (c - b) * lm / lc * 0.1\n",
        "    a = b + (a - b) * lm / la * 0.3\n",
        "    c = b + (c - b) * lm / lc * 0.3\n",
        "    return b, a, c, d, e\n",
        "\n",
        "def draw_pi_slice(draw, center, point1, point2, fill):\n",
        "    radius = np.linalg.norm(point1 - center)\n",
        "    bbox = [\n",
        "        center[0] - radius, center[1] - radius,\n",
        "        center[0] + radius, center[1] + radius\n",
        "    ]\n",
        "\n",
        "    def angle_between(p, center):\n",
        "        dx = p[0] - center[0]\n",
        "        dy = p[1] - center[1]\n",
        "        angle = np.degrees(np.arctan2(dy, dx)) % 360\n",
        "        return angle\n",
        "\n",
        "    start_angle = angle_between(point1, center)\n",
        "    end_angle = angle_between(point2, center)\n",
        "    if (end_angle - start_angle) % 360 > 180:\n",
        "        end_angle, start_angle = start_angle, end_angle\n",
        "    draw.pieslice(bbox, start=start_angle, end=end_angle, fill=fill)\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "w, h = athlete_frames.shape[2], athlete_frames.shape[1]\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or 'XVID'\n",
        "out = cv2.VideoWriter('output_video.mp4', fourcc, FPS, (w, h))\n",
        "\n",
        "# Write images to video\n",
        "for t in tqdm(range(athlete_frames.shape[0])):\n",
        "    landmarks = athlete_landmarks[t]\n",
        "    frame = Image.fromarray(athlete_frames[t])\n",
        "    draw = ImageDraw.Draw(frame)\n",
        "    angle_points = get_angle_points(standardize_landmarks(landmarks))\n",
        "    for i in range(len(angle_points)):\n",
        "        if usefulness[i] >= 0.5:\n",
        "            a, b, c, d, e = angle_points[names[i]]\n",
        "            r, g = int(255 * (1 - similarity[t, i])), int(255 * similarity[t, i])\n",
        "            draw.line([a[0]*w, a[1]*h, b[0]*w, b[1]*h], fill=(r, g, 0), width=5)\n",
        "            draw.line([a[0]*w, a[1]*h, c[0]*w, c[1]*h], fill=(r, g, 0), width=5)\n",
        "            draw_pi_slice(draw,\n",
        "                          np.array([a[0]*w, a[1]*h]),\n",
        "                          np.array([d[0]*w, d[1]*h]),\n",
        "                          np.array([e[0]*w, e[1]*h]),\n",
        "                          (r, g, 0))\n",
        "    out.write(cv2.cvtColor(np.array(frame), cv2.COLOR_BGR2RGB))  # Add frame\n",
        "\n",
        "# Release everything\n",
        "out.release()\n",
        "print(\"Video saved as output_video.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4435c9d-3b88-4706-9a3e-af30cfe3ee32",
      "metadata": {
        "id": "e4435c9d-3b88-4706-9a3e-af30cfe3ee32"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}